{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "BootcampAlura_Modulo4.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-01-13T01:35:57.085222Z",
          "iopub.execute_input": "2022-01-13T01:35:57.085816Z",
          "iopub.status.idle": "2022-01-13T01:35:57.095345Z",
          "shell.execute_reply.started": "2022-01-13T01:35:57.085774Z",
          "shell.execute_reply": "2022-01-13T01:35:57.094402Z"
        },
        "trusted": true,
        "id": "11dHHrocMEV-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_excel(\"https://github.com/alura-cursos/covid-19-clinical/blob/main/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T01:36:05.490938Z",
          "iopub.execute_input": "2022-01-13T01:36:05.491168Z",
          "iopub.status.idle": "2022-01-13T01:36:10.015146Z",
          "shell.execute_reply.started": "2022-01-13T01:36:05.491141Z",
          "shell.execute_reply": "2022-01-13T01:36:10.014208Z"
        },
        "trusted": true,
        "id": "BXTyDNXFMEWA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tratamento da Base 1\")\n",
        "\n",
        "pacientes_UTI = dados[['PATIENT_VISIT_IDENTIFIER','ICU']].query('ICU == 1').groupby('PATIENT_VISIT_IDENTIFIER').min()\n",
        "dados_tratados = dados.query('ICU != 1').drop('ICU', axis=1)\n",
        "dados_tratados = dados_tratados.join(pacientes_UTI, on='PATIENT_VISIT_IDENTIFIER', how='left')\n",
        "dados_tratados['ICU'] = dados_tratados['ICU'].fillna(0) \n",
        "print(\"\\nRemovemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\")\n",
        "print(f\"Distribuição de ICU na base tratada (%)\\n{dados_tratados['ICU'].value_counts(normalize=True)*100}\")\n",
        "\n",
        "features_continuas_colunas = dados_tratados.iloc[:, 13:-2].columns\n",
        "features_continuas = dados_tratados.groupby(\"PATIENT_VISIT_IDENTIFIER\",as_index=False)[features_continuas_colunas].fillna(method='bfill').fillna(method='ffill')\n",
        "features_categoricas = dados_tratados.iloc[:, :13]\n",
        "saida = dados_tratados.iloc[:, -2:]\n",
        "dados_tratados = pd.concat([features_categoricas, features_continuas, saida], ignore_index=True,axis=1)\n",
        "dados_tratados.columns = dados.columns\n",
        "print(\"\\nAjustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\")\n",
        "\n",
        "descricao = dados_tratados.describe().T\n",
        "colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "if len(colunas_sem_variacao) !=0:\n",
        "  dados_tratados.drop(colunas_sem_variacao, axis=1)\n",
        "  print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "colunas_categoricas = list(set(dados_tratados.columns)-set(dados_tratados.describe().columns)-{'WINDOW'})\n",
        "colunas_categoricas\n",
        "if len(colunas_categoricas) ==1:\n",
        "  LE = preprocessing.LabelEncoder()\n",
        "  LE.fit(np.ravel(dados_tratados[colunas_categoricas]))\n",
        "  dados_tratados[colunas_categoricas] = LE.transform(np.ravel(dados_tratados[colunas_categoricas]))\n",
        "  print(f\"\\nColuna com objeto categórico ({colunas_categoricas[0]}) foi transformada em numérica\")\n",
        "else:\n",
        "  print(f\"\\nColunas com objetos categóricos precisam ser tratados: {', '.join(colunas_categoricas)}\")\n",
        "\n",
        "\n",
        "linhas_com_nam = dados_tratados.describe(include='all').loc['count'].max()-dados_tratados.describe(include='all').loc['count'].min()\n",
        "if linhas_com_nam !=0:\n",
        "  if linhas_com_nam <= len(dados_tratados)*.1:\n",
        "    dados_tratados.dropna(inplace=True)\n",
        "    print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) foram eliminadas\")\n",
        "  else:\n",
        "    print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) precisam ser tratadas\")\n",
        "\n",
        "dados_tratados.reset_index(drop=True, inplace=True)\n",
        "print(f\"\\nO index foi resetado: {dados_tratados.index}\")\n",
        "\n",
        "print(f\"\\nFormato final do DataFrame dados_tratados: {dados_tratados.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T01:36:11.633841Z",
          "iopub.execute_input": "2022-01-13T01:36:11.634513Z",
          "iopub.status.idle": "2022-01-13T01:36:11.703375Z",
          "shell.execute_reply.started": "2022-01-13T01:36:11.634461Z",
          "shell.execute_reply": "2022-01-13T01:36:11.702371Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN4V01nBMEWC",
        "outputId": "d14f8a76-2319-4cec-a4d1-267409fd98f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tratamento da Base 1\n",
            "\n",
            "Removemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\n",
            "Distribuição de ICU na base tratada (%)\n",
            "0.0    67.375887\n",
            "1.0    32.624113\n",
            "Name: ICU, dtype: float64\n",
            "\n",
            "Ajustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\n",
            "\n",
            "Removemos as colunas que os valores são iguais para todas as linhas\n",
            "\n",
            "Coluna com objeto categórico (AGE_PERCENTIL) foi transformada em numérica\n",
            "\n",
            "As linhas ainda com Nam (5.0 linhas, 0.36% do total) foram eliminadas\n",
            "\n",
            "O index foi resetado: RangeIndex(start=0, stop=1405, step=1)\n",
            "\n",
            "Formato final do DataFrame dados_tratados: (1405, 231)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Segunda Base Tratada\")\n",
        "\n",
        "age_percentil = np.array(dados_tratados['AGE_PERCENTIL']).reshape(-1, 1)\n",
        "OHE = preprocessing.OneHotEncoder()\n",
        "age_percentil_OHE = pd.DataFrame(OHE.fit_transform(age_percentil).toarray())\n",
        "dados_tratados_OHE = pd.concat([dados_tratados.drop('AGE_PERCENTIL', axis=1), age_percentil_OHE], ignore_index=True, axis=1)\n",
        "colunas = list(dados_tratados.columns)\n",
        "colunas.remove('AGE_PERCENTIL')\n",
        "colunas_novas = list(dados['AGE_PERCENTIL'].unique())\n",
        "colunas_novas.sort()\n",
        "colunas.extend(colunas_novas)\n",
        "dados_tratados_OHE.columns = colunas\n",
        "print(f\"\\nTrocamos o campo AGE_PERCENTIL pelos campos binários {', '.join(colunas_novas)}\")\n",
        "\n",
        "print(f\"\\nFormato final do DataFrame dados_tratados_OHE: {dados_tratados_OHE.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI0sdLsZSUIk",
        "outputId": "929947ff-11b7-4dea-8c25-07e3b81e6976"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segunda Base Tratada\n",
            "\n",
            "Trocamos o campo AGE_PERCENTIL pelos campos binários 10th, 20th, 30th, 40th, 50th, 60th, 70th, 80th, 90th, Above 90th\n",
            "\n",
            "Formato final do DataFrame dados_tratados_OHE: (1405, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def roda_modelo_cv(modelo, dados, n_splits, n_repeats):\n",
        "\n",
        "    np.random.seed(4367)\n",
        "    dados = dados.sample(frac=1).reset_index(drop=True)\n",
        "    y = dados[\"ICU\"]\n",
        "    x = dados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "    \n",
        "    \n",
        "    cv = RepeatedKFold(n_splits = n_splits, n_repeats=n_repeats)\n",
        "    resultados=cross_validate(modelo, x, y, cv=cv, scoring='roc_auc')\n",
        "    \n",
        "    auc_medio = np.mean(resultados['test_score'])\n",
        "    auc_std = np.std(resultados['test_score'])\n",
        "    \n",
        " \n",
        "    print(f\"AUC Médio {auc_medio} Intervalo {auc_medio - (2*auc_std)} - {auc_medio + (2*auc_std)}\")"
      ],
      "metadata": {
        "id": "9hO_3WQpbqMA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roda_modelo_stratified_cv(modelo, dados, n_splits, n_repeats):\n",
        "\n",
        "    np.random.seed(4367)\n",
        "    dados = dados.sample(frac=1).reset_index(drop=True)\n",
        "    y = dados[\"ICU\"]\n",
        "    x = dados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "    \n",
        "    \n",
        "    cv = RepeatedStratifiedKFold(n_splits = n_splits, n_repeats=n_repeats)\n",
        "    resultados=cross_validate(modelo, x, y, cv=cv, scoring='roc_auc')\n",
        "    \n",
        "    auc_medio = np.mean(resultados['test_score'])\n",
        "    auc_std = np.std(resultados['test_score'])\n",
        "    \n",
        " \n",
        "    print(f\"AUC Médio {auc_medio} Intervalo {auc_medio - (2*auc_std)} - {auc_medio + (2*auc_std)}\")"
      ],
      "metadata": {
        "id": "jmASe-VEOIVr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roda_modelo_cv(LogisticRegression(max_iter=9000),dados_tratados.query('WINDOW == \"0-2\"'),5,10)"
      ],
      "metadata": {
        "id": "OLyJ_AJdL-Cb",
        "outputId": "47d17533-e8c6-4f3a-c4a0-b9849efe4db3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Médio 0.7585856878805273 Intervalo 0.6728163048854148 - 0.8443550708756398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roda_modelo_stratified_cv(LogisticRegression(max_iter=9000),dados_tratados.query('WINDOW == \"0-2\"'),5,10)"
      ],
      "metadata": {
        "id": "gHhPeaMZMdK8",
        "outputId": "778aac48-cff4-4839-f6d2-af0fd8965032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Médio 0.7571566931764301 Intervalo 0.6521306135217886 - 0.8621827728310716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados_tratados.query('WINDOW == \"0-2\"').ICU.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "F8jYxCb_MvPD",
        "outputId": "ef8d2c38-ce85-474d-895b-01b893910517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    189\n",
              "1.0    163\n",
              "Name: ICU, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class modelos:\n",
        "  def __init__(self, a, b, **kwargs):\n",
        "    self.a = a\n",
        "    self.b = b\n",
        "  def metodo_a (self, c):\n",
        "    return self.a*self.b*c"
      ],
      "metadata": {
        "id": "ITT3UWkJQOPC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = modelos(10,2)"
      ],
      "metadata": {
        "id": "QXrdEHc6B5gx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.metodo_a(1)"
      ],
      "metadata": {
        "id": "l9Hg47j-B8w6",
        "outputId": "034e922a-c721-4fb4-b6b2-64ba1762fb7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(LogisticRegression)"
      ],
      "metadata": {
        "id": "ud3nDvAICAI6",
        "outputId": "34e4b6a6-b03d-40b0-b90e-5091a3c19b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class LogisticRegression in module sklearn.linear_model._logistic:\n",
            "\n",
            "class LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
            " |  LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
            " |  \n",
            " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
            " |  \n",
            " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
            " |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
            " |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
            " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
            " |  'sag', 'saga' and 'newton-cg' solvers.)\n",
            " |  \n",
            " |  This class implements regularized logistic regression using the\n",
            " |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
            " |  that regularization is applied by default**. It can handle both dense\n",
            " |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
            " |  floats for optimal performance; any other input format will be converted\n",
            " |  (and copied).\n",
            " |  \n",
            " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
            " |  with primal formulation, or no regularization. The 'liblinear' solver\n",
            " |  supports both L1 and L2 regularization, with a dual formulation only for\n",
            " |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
            " |  'saga' solver.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\n",
            " |      Specify the norm of the penalty:\n",
            " |  \n",
            " |      - `'none'`: no penalty is added;\n",
            " |      - `'l2'`: add a L2 penalty term and it is the default choice;\n",
            " |      - `'l1'`: add a L1 penalty term;\n",
            " |      - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
            " |  \n",
            " |      .. warning::\n",
            " |         Some penalties may not work with some solvers. See the parameter\n",
            " |         `solver` below, to know the compatibility between the penalty and\n",
            " |         solver.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
            " |  \n",
            " |  dual : bool, default=False\n",
            " |      Dual or primal formulation. Dual formulation is only implemented for\n",
            " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
            " |      n_samples > n_features.\n",
            " |  \n",
            " |  tol : float, default=1e-4\n",
            " |      Tolerance for stopping criteria.\n",
            " |  \n",
            " |  C : float, default=1.0\n",
            " |      Inverse of regularization strength; must be a positive float.\n",
            " |      Like in support vector machines, smaller values specify stronger\n",
            " |      regularization.\n",
            " |  \n",
            " |  fit_intercept : bool, default=True\n",
            " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
            " |      added to the decision function.\n",
            " |  \n",
            " |  intercept_scaling : float, default=1\n",
            " |      Useful only when the solver 'liblinear' is used\n",
            " |      and self.fit_intercept is set to True. In this case, x becomes\n",
            " |      [x, self.intercept_scaling],\n",
            " |      i.e. a \"synthetic\" feature with constant value equal to\n",
            " |      intercept_scaling is appended to the instance vector.\n",
            " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
            " |  \n",
            " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
            " |      as all other features.\n",
            " |      To lessen the effect of regularization on synthetic feature weight\n",
            " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
            " |  \n",
            " |  class_weight : dict or 'balanced', default=None\n",
            " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
            " |      If not given, all classes are supposed to have weight one.\n",
            " |  \n",
            " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
            " |      weights inversely proportional to class frequencies in the input data\n",
            " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
            " |  \n",
            " |      Note that these weights will be multiplied with sample_weight (passed\n",
            " |      through the fit method) if sample_weight is specified.\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *class_weight='balanced'*\n",
            " |  \n",
            " |  random_state : int, RandomState instance, default=None\n",
            " |      Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
            " |      data. See :term:`Glossary <random_state>` for details.\n",
            " |  \n",
            " |  solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
            " |  \n",
            " |      Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
            " |      To choose a solver, you might want to consider the following aspects:\n",
            " |  \n",
            " |          - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
            " |            and 'saga' are faster for large ones;\n",
            " |          - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
            " |            'lbfgs' handle multinomial loss;\n",
            " |          - 'liblinear' is limited to one-versus-rest schemes.\n",
            " |  \n",
            " |      .. warning::\n",
            " |         The choice of the algorithm depends on the penalty chosen:\n",
            " |         Supported penalties by solver:\n",
            " |  \n",
            " |         - 'newton-cg'   -   ['l2', 'none']\n",
            " |         - 'lbfgs'       -   ['l2', 'none']\n",
            " |         - 'liblinear'   -   ['l1', 'l2']\n",
            " |         - 'sag'         -   ['l2', 'none']\n",
            " |         - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\n",
            " |  \n",
            " |      .. note::\n",
            " |         'sag' and 'saga' fast convergence is only guaranteed on\n",
            " |         features with approximately the same scale. You can\n",
            " |         preprocess the data with a scaler from :mod:`sklearn.preprocessing`.\n",
            " |  \n",
            " |      .. seealso::\n",
            " |         Refer to the User Guide for more information regarding\n",
            " |         :class:`LogisticRegression` and more specifically the\n",
            " |         `Table <https://scikit-learn.org/dev/modules/linear_model.html#logistic-regression>`_\n",
            " |         summarazing solver/penalty supports.\n",
            " |         <!--\n",
            " |         # noqa: E501\n",
            " |         -->\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         Stochastic Average Gradient descent solver.\n",
            " |      .. versionadded:: 0.19\n",
            " |         SAGA solver.\n",
            " |      .. versionchanged:: 0.22\n",
            " |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
            " |  \n",
            " |  max_iter : int, default=100\n",
            " |      Maximum number of iterations taken for the solvers to converge.\n",
            " |  \n",
            " |  multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
            " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
            " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
            " |      across the entire probability distribution, *even when the data is\n",
            " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
            " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
            " |      and otherwise selects 'multinomial'.\n",
            " |  \n",
            " |      .. versionadded:: 0.18\n",
            " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
            " |      .. versionchanged:: 0.22\n",
            " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
            " |  \n",
            " |  verbose : int, default=0\n",
            " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
            " |      number for verbosity.\n",
            " |  \n",
            " |  warm_start : bool, default=False\n",
            " |      When set to True, reuse the solution of the previous call to fit as\n",
            " |      initialization, otherwise, just erase the previous solution.\n",
            " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      Number of CPU cores used when parallelizing over classes if\n",
            " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
            " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
            " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
            " |      context. ``-1`` means using all processors.\n",
            " |      See :term:`Glossary <n_jobs>` for more details.\n",
            " |  \n",
            " |  l1_ratio : float, default=None\n",
            " |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
            " |      used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
            " |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
            " |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
            " |      combination of L1 and L2.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  \n",
            " |  classes_ : ndarray of shape (n_classes, )\n",
            " |      A list of class labels known to the classifier.\n",
            " |  \n",
            " |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
            " |      Coefficient of the features in the decision function.\n",
            " |  \n",
            " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
            " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
            " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
            " |  \n",
            " |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
            " |      Intercept (a.k.a. bias) added to the decision function.\n",
            " |  \n",
            " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
            " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
            " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
            " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
            " |      outcome 0 (False).\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
            " |      Actual number of iterations for all classes. If binary or multinomial,\n",
            " |      it returns only 1 element. For liblinear solver, only the maximum\n",
            " |      number of iteration across all classes is given.\n",
            " |  \n",
            " |      .. versionchanged:: 0.20\n",
            " |  \n",
            " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
            " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  SGDClassifier : Incrementally trained logistic regression (when given\n",
            " |      the parameter ``loss=\"log\"``).\n",
            " |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The underlying C implementation uses a random number generator to\n",
            " |  select features when fitting the model. It is thus not uncommon,\n",
            " |  to have slightly different results for the same input data. If\n",
            " |  that happens, try with a smaller tol parameter.\n",
            " |  \n",
            " |  Predict output may not match that of standalone liblinear in certain\n",
            " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
            " |  in the narrative documentation.\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  \n",
            " |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
            " |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
            " |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
            " |  \n",
            " |  LIBLINEAR -- A Library for Large Linear Classification\n",
            " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
            " |  \n",
            " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
            " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
            " |      https://hal.inria.fr/hal-00860051/document\n",
            " |  \n",
            " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
            " |      SAGA: A Fast Incremental Gradient Method With Support\n",
            " |      for Non-Strongly Convex Composite Objectives\n",
            " |      https://arxiv.org/abs/1407.0202\n",
            " |  \n",
            " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
            " |      methods for logistic regression and maximum entropy models.\n",
            " |      Machine Learning 85(1-2):41-75.\n",
            " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.datasets import load_iris\n",
            " |  >>> from sklearn.linear_model import LogisticRegression\n",
            " |  >>> X, y = load_iris(return_X_y=True)\n",
            " |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
            " |  >>> clf.predict(X[:2, :])\n",
            " |  array([0, 0])\n",
            " |  >>> clf.predict_proba(X[:2, :])\n",
            " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
            " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
            " |  >>> clf.score(X, y)\n",
            " |  0.97...\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      LogisticRegression\n",
            " |      sklearn.linear_model._base.LinearClassifierMixin\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      sklearn.linear_model._base.SparseCoefMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None)\n",
            " |      Fit the model according to the given training data.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          Training vector, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,)\n",
            " |          Target vector relative to X.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,) default=None\n",
            " |          Array of weights that are assigned to individual samples.\n",
            " |          If not provided, then each sample is given unit weight.\n",
            " |      \n",
            " |          .. versionadded:: 0.17\n",
            " |             *sample_weight* support to LogisticRegression.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |          Fitted estimator.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      The SAGA solver supports both float64 and float32 bit arrays.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Predict logarithm of probability estimates.\n",
            " |      \n",
            " |      The returned estimates for all classes are ordered by the\n",
            " |      label of classes.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Vector to be scored, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      T : array-like of shape (n_samples, n_classes)\n",
            " |          Returns the log-probability of the sample for each class in the\n",
            " |          model, where classes are ordered as they are in ``self.classes_``.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Probability estimates.\n",
            " |      \n",
            " |      The returned estimates for all classes are ordered by the\n",
            " |      label of classes.\n",
            " |      \n",
            " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
            " |      the softmax function is used to find the predicted probability of\n",
            " |      each class.\n",
            " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
            " |      of each class assuming it to be positive using the logistic function.\n",
            " |      and normalize these values across all the classes.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Vector to be scored, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      T : array-like of shape (n_samples, n_classes)\n",
            " |          Returns the probability of the sample for each class in the model,\n",
            " |          where classes are ordered as they are in ``self.classes_``.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Predict confidence scores for samples.\n",
            " |      \n",
            " |      The confidence score for a sample is proportional to the signed\n",
            " |      distance of that sample to the hyperplane.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The data matrix for which we want to get the confidence scores.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
            " |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
            " |          this class would be predicted.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict class labels for samples in X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The data matrix for which we want to get the predictions.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,)\n",
            " |          Vector containing the class labels for each sample.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
            " |  \n",
            " |  densify(self)\n",
            " |      Convert coefficient matrix to dense array format.\n",
            " |      \n",
            " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
            " |      default format of ``coef_`` and is required for fitting, so calling\n",
            " |      this method is only required on models that have previously been\n",
            " |      sparsified; otherwise, it is a no-op.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  sparsify(self)\n",
            " |      Convert coefficient matrix to sparse format.\n",
            " |      \n",
            " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
            " |      L1-regularized models can be much more memory- and storage-efficient\n",
            " |      than the usual numpy.ndarray representation.\n",
            " |      \n",
            " |      The ``intercept_`` member is not converted.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |          Fitted estimator.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
            " |      this may actually *increase* memory usage, so use this method with\n",
            " |      care. A rule of thumb is that the number of zero elements, which can\n",
            " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
            " |      to provide significant benefits.\n",
            " |      \n",
            " |      After calling this method, further fitting with the partial_fit\n",
            " |      method (if any) will not work until you call densify.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicionario  = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "cv = RepeatedKFold(n_splits = 5, n_repeats=10)\n",
        "y = dados_tratados[\"ICU\"]\n",
        "x = dados_tratados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=6000),dicionario, scoring=\"roc_auc\",cv=cv,return_train_score=True)\n",
        "resultados= grid.fit(x,y)"
      ],
      "metadata": {
        "id": "yUt-aSe2C_1r"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Melhor: %f usando %s' %(resultados.best_score_, resultados.best_params_))\n",
        "means = resultados.cv_results_['mean_test_score']\n",
        "stds = resultados.cv_results_['std_test_score']\n",
        "params = resultados.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f'{mean:.3%} ({(mean-2*stdev):.3%} - {(mean+2*stdev):.3%}): {param}')"
      ],
      "metadata": {
        "id": "DzC5ojDGi4By",
        "outputId": "306a62fe-c79f-440c-f946-a4822d596dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor: 0.874238 usando {'solver': 'lbfgs'}\n",
            "87.424% (82.996% - 91.852%): {'solver': 'newton-cg'}\n",
            "87.424% (82.996% - 91.852%): {'solver': 'lbfgs'}\n",
            "87.403% (83.001% - 91.804%): {'solver': 'liblinear'}\n",
            "87.402% (83.001% - 91.803%): {'solver': 'sag'}\n",
            "87.401% (83.000% - 91.802%): {'solver': 'saga'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Melhor: {resultados_OHE.best_score_:.3%} usando {resultados_OHE.best_params_}')\n",
        "means = resultados_OHE.cv_results_['mean_test_score']\n",
        "stds = resultados_OHE.cv_results_['std_test_score']\n",
        "params = resultados_OHE.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f'{mean:.3%} ({(mean-2*stdev):.3%} - {(mean+2*stdev):.3%}): {param}')"
      ],
      "metadata": {
        "id": "tvUx9T-mkFEU",
        "outputId": "ce4e66e1-4479-406d-d438-9b54d8a230d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor: 87.564% usando {'solver': 'newton-cg'}\n",
            "87.564% (83.292% - 91.836%): {'solver': 'newton-cg'}\n",
            "87.563% (83.292% - 91.834%): {'solver': 'lbfgs'}\n",
            "87.529% (83.276% - 91.783%): {'solver': 'liblinear'}\n",
            "87.529% (83.274% - 91.783%): {'solver': 'sag'}\n",
            "87.529% (83.276% - 91.783%): {'solver': 'saga'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.__dict__"
      ],
      "metadata": {
        "id": "aVLJxupBmwnd",
        "outputId": "37daf70d-733a-4a36-f79f-2a70045df591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_estimator_': LogisticRegression(max_iter=6000),\n",
              " 'best_index_': 1,\n",
              " 'best_params_': {'solver': 'lbfgs'},\n",
              " 'best_score_': 0.8742378145349715,\n",
              " 'cv': RepeatedKFold(n_repeats=10, n_splits=5, random_state=None),\n",
              " 'cv_results_': {'mean_fit_time': array([0.14962143, 0.31480327, 0.08861282, 0.62619057, 1.20924917]),\n",
              "  'mean_score_time': array([0.00825964, 0.00792744, 0.00793491, 0.00661498, 0.00704105]),\n",
              "  'mean_test_score': array([0.87423761, 0.87423781, 0.87402662, 0.87402155, 0.87400666]),\n",
              "  'mean_train_score': array([0.89888246, 0.8988787 , 0.89870421, 0.89868739, 0.89865311]),\n",
              "  'param_solver': masked_array(data=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
              "               mask=[False, False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'solver': 'newton-cg'},\n",
              "   {'solver': 'lbfgs'},\n",
              "   {'solver': 'liblinear'},\n",
              "   {'solver': 'sag'},\n",
              "   {'solver': 'saga'}],\n",
              "  'rank_test_score': array([2, 1, 3, 4, 5], dtype=int32),\n",
              "  'split0_test_score': array([0.90375142, 0.90375142, 0.90343564, 0.90356196, 0.90356196]),\n",
              "  'split0_train_score': array([0.8945506 , 0.89456118, 0.89464586, 0.89461058, 0.89458941]),\n",
              "  'split10_test_score': array([0.86350544, 0.86355878, 0.86270536, 0.86265202, 0.86286537]),\n",
              "  'split10_train_score': array([0.90024804, 0.90028859, 0.90009693, 0.90008219, 0.90001953]),\n",
              "  'split11_test_score': array([0.86554726, 0.86548507, 0.86623134, 0.86641791, 0.86616915]),\n",
              "  'split11_train_score': array([0.90048812, 0.9004775 , 0.90051287, 0.90053763, 0.90049873]),\n",
              "  'split12_test_score': array([0.86271088, 0.86265271, 0.8617801 , 0.86160558, 0.86160558]),\n",
              "  'split12_train_score': array([0.90220446, 0.9022188 , 0.9023335 , 0.90231916, 0.90230124]),\n",
              "  'split13_test_score': array([0.89127859, 0.89121934, 0.88997512, 0.88985662, 0.88979737]),\n",
              "  'split13_train_score': array([0.89572438, 0.89568868, 0.8954495 , 0.89536739, 0.89531027]),\n",
              "  'split14_test_score': array([0.88912277, 0.88917966, 0.88935032, 0.88952099, 0.88940721]),\n",
              "  'split14_train_score': array([0.89431492, 0.89432934, 0.89422841, 0.89420679, 0.89415632]),\n",
              "  'split15_test_score': array([0.86421871, 0.86416152, 0.86404713, 0.86410432, 0.86404713]),\n",
              "  'split15_train_score': array([0.89844467, 0.89843747, 0.89813152, 0.89820711, 0.89815311]),\n",
              "  'split16_test_score': array([0.8757085 , 0.87565067, 0.87536148, 0.87541932, 0.87541932]),\n",
              "  'split16_train_score': array([0.89930903, 0.89931621, 0.89911879, 0.89912597, 0.89901829]),\n",
              "  'split17_test_score': array([0.83152174, 0.83152174, 0.83185791, 0.83168983, 0.83174585]),\n",
              "  'split17_train_score': array([0.90919227, 0.90920675, 0.90918141, 0.90915245, 0.90914159]),\n",
              "  'split18_test_score': array([0.9049236 , 0.90498019, 0.90452745, 0.90452745, 0.90435767]),\n",
              "  'split18_train_score': array([0.89206418, 0.89208223, 0.89170321, 0.89172126, 0.89167073]),\n",
              "  'split19_test_score': array([0.88772057, 0.88772057, 0.88741842, 0.88747885, 0.88753928]),\n",
              "  'split19_train_score': array([0.89647926, 0.89652904, 0.89626948, 0.89628015, 0.89624815]),\n",
              "  'split1_test_score': array([0.88561077, 0.88561077, 0.88492063, 0.88515068, 0.8852657 ]),\n",
              "  'split1_train_score': array([0.896563  , 0.89654144, 0.89654144, 0.89648393, 0.89641563]),\n",
              "  'split20_test_score': array([0.87218329, 0.87218329, 0.87212938, 0.87218329, 0.8722372 ]),\n",
              "  'split20_train_score': array([0.90111894, 0.90111527, 0.90055397, 0.9005613 , 0.90053929]),\n",
              "  'split21_test_score': array([0.86809779, 0.86809779, 0.86768038, 0.86779964, 0.86762075]),\n",
              "  'split21_train_score': array([0.90133333, 0.90133333, 0.90143672, 0.90141176, 0.90141533]),\n",
              "  'split22_test_score': array([0.88498055, 0.88498055, 0.88469458, 0.88452299, 0.88463738]),\n",
              "  'split22_train_score': array([0.89595384, 0.89589625, 0.8955507 , 0.8955471 , 0.8955471 ]),\n",
              "  'split23_test_score': array([0.85224905, 0.85237161, 0.85231033, 0.85224905, 0.85224905]),\n",
              "  'split23_train_score': array([0.90474063, 0.90470516, 0.90447111, 0.90446402, 0.90439664]),\n",
              "  'split24_test_score': array([0.91094715, 0.91100435, 0.91008922, 0.9104324 , 0.9104324 ]),\n",
              "  'split24_train_score': array([0.89020549, 0.8901875 , 0.8901623 , 0.89012631, 0.89006151]),\n",
              "  'split25_test_score': array([0.84552239, 0.8454602 , 0.84577114, 0.84558458, 0.84552239]),\n",
              "  'split25_train_score': array([0.90456989, 0.90456636, 0.90430461, 0.90423741, 0.90421265]),\n",
              "  'split26_test_score': array([0.87646396, 0.87652027, 0.87601351, 0.87578829, 0.87584459]),\n",
              "  'split26_train_score': array([0.89872036, 0.89870228, 0.89832273, 0.89832996, 0.89831912]),\n",
              "  'split27_test_score': array([0.88514851, 0.88514851, 0.88476348, 0.88459846, 0.88454345]),\n",
              "  'split27_train_score': array([0.89676844, 0.89675387, 0.89675387, 0.8967211 , 0.89667741]),\n",
              "  'split28_test_score': array([0.86349093, 0.86349093, 0.86355018, 0.86337244, 0.86360943]),\n",
              "  'split28_train_score': array([0.90155396, 0.90153611, 0.90149684, 0.90150755, 0.90145043]),\n",
              "  'split29_test_score': array([0.90529279, 0.9053491 , 0.90472973, 0.90456081, 0.90472973]),\n",
              "  'split29_train_score': array([0.89103167, 0.89106058, 0.89120156, 0.89114734, 0.89114011]),\n",
              "  'split2_test_score': array([0.86964618, 0.86975572, 0.87139884, 0.87145361, 0.87117976]),\n",
              "  'split2_train_score': array([0.89940487, 0.89943769, 0.89897093, 0.89902563, 0.89901104]),\n",
              "  'split30_test_score': array([0.84456079, 0.84456079, 0.84380454, 0.84397906, 0.84397906]),\n",
              "  'split30_train_score': array([0.90424762, 0.90421536, 0.90402179, 0.90401821, 0.90396444]),\n",
              "  'split31_test_score': array([0.87696133, 0.87696133, 0.87679558, 0.87668508, 0.87668508]),\n",
              "  'split31_train_score': array([0.89910558, 0.89910922, 0.89852385, 0.89861475, 0.89856021]),\n",
              "  'split32_test_score': array([0.85582233, 0.85582233, 0.85660264, 0.85666267, 0.85660264]),\n",
              "  'split32_train_score': array([0.90115532, 0.90112684, 0.90087405, 0.90083489, 0.90080641]),\n",
              "  'split33_test_score': array([0.88864198, 0.88858025, 0.88864198, 0.8882716 , 0.8882716 ]),\n",
              "  'split33_train_score': array([0.89409077, 0.89407306, 0.89422181, 0.89420056, 0.89416161]),\n",
              "  'split34_test_score': array([0.87456541, 0.87472838, 0.87299   , 0.87288136, 0.87293568]),\n",
              "  'split34_train_score': array([0.89878131, 0.89878497, 0.89859843, 0.89855088, 0.89848139]),\n",
              "  'split35_test_score': array([0.82612613, 0.82612613, 0.82640766, 0.82657658, 0.82668919]),\n",
              "  'split35_train_score': array([0.90916715, 0.90916353, 0.90891773, 0.90890688, 0.90885989]),\n",
              "  'split36_test_score': array([0.883517  , 0.883517  , 0.88369475, 0.883754  , 0.883754  ]),\n",
              "  'split36_train_score': array([0.89820186, 0.89819472, 0.89834823, 0.89837678, 0.8983161 ]),\n",
              "  'split37_test_score': array([0.89830793, 0.89830793, 0.8966831 , 0.89662707, 0.89662707]),\n",
              "  'split37_train_score': array([0.89150856, 0.89153028, 0.89141082, 0.89137462, 0.89134928]),\n",
              "  'split38_test_score': array([0.8740096 , 0.8740096 , 0.87340936, 0.87376951, 0.87370948]),\n",
              "  'split38_train_score': array([0.89797953, 0.89798309, 0.89778015, 0.89776591, 0.89778371]),\n",
              "  'split39_test_score': array([0.86904358, 0.86898698, 0.86949632, 0.86960951, 0.86960951]),\n",
              "  'split39_train_score': array([0.90082842, 0.90080315, 0.90035916, 0.90039165, 0.90036638]),\n",
              "  'split3_test_score': array([0.83406532, 0.8339527 , 0.83288288, 0.83293919, 0.83293919]),\n",
              "  'split3_train_score': array([0.91035281, 0.91036365, 0.90990818, 0.9099118 , 0.90987565]),\n",
              "  'split40_test_score': array([0.88201272, 0.88201272, 0.88316946, 0.88305379, 0.88305379]),\n",
              "  'split40_train_score': array([0.89834706, 0.89833988, 0.89769378, 0.89769378, 0.89763635]),\n",
              "  'split41_test_score': array([0.86015786, 0.86010066, 0.85901396, 0.85918554, 0.85901396]),\n",
              "  'split41_train_score': array([0.90117307, 0.90119826, 0.90107588, 0.90102549, 0.90105068]),\n",
              "  'split42_test_score': array([0.88016679, 0.88010636, 0.87962292, 0.87962292, 0.87950205]),\n",
              "  'split42_train_score': array([0.89834239, 0.89836017, 0.89784105, 0.89784105, 0.89778772]),\n",
              "  'split43_test_score': array([0.86541981, 0.86541981, 0.86582018, 0.86576298, 0.86570579]),\n",
              "  'split43_train_score': array([0.90124506, 0.90116947, 0.9009571 , 0.90090311, 0.90083112]),\n",
              "  'split44_test_score': array([0.9038739, 0.9038739, 0.9034299, 0.9034299, 0.9034854]),\n",
              "  'split44_train_score': array([0.89422857, 0.89422131, 0.89420679, 0.89411602, 0.89409787]),\n",
              "  'split45_test_score': array([0.87470289, 0.87481607, 0.87413696, 0.87413696, 0.87413696]),\n",
              "  'split45_train_score': array([0.89730178, 0.89732344, 0.89714296, 0.89713213, 0.89713574]),\n",
              "  'split46_test_score': array([0.92863872, 0.92863872, 0.92828545, 0.92816769, 0.92816769]),\n",
              "  'split46_train_score': array([0.88766873, 0.88766158, 0.88754361, 0.88751859, 0.88748284]),\n",
              "  'split47_test_score': array([0.84299547, 0.84293418, 0.84201495, 0.84207623, 0.84189239]),\n",
              "  'split47_train_score': array([0.9053293 , 0.9053364 , 0.90535058, 0.90537186, 0.90530803]),\n",
              "  'split48_test_score': array([0.85821322, 0.858442  , 0.858442  , 0.85832761, 0.85832761]),\n",
              "  'split48_train_score': array([0.90475453, 0.90471134, 0.90454577, 0.90454217, 0.90452417]),\n",
              "  'split49_test_score': array([0.89423814, 0.89407383, 0.89478585, 0.89467631, 0.89473108]),\n",
              "  'split49_train_score': array([0.89572545, 0.89574004, 0.89572545, 0.89564888, 0.89565617]),\n",
              "  'split4_test_score': array([0.88704854, 0.88710605, 0.8857833 , 0.88589832, 0.8857833 ]),\n",
              "  'split4_train_score': array([0.89427694, 0.89418708, 0.89397142, 0.89394266, 0.89394626]),\n",
              "  'split5_test_score': array([0.88251273, 0.88251273, 0.88438031, 0.88438031, 0.88438031]),\n",
              "  'split5_train_score': array([0.89681448, 0.8968217 , 0.89644269, 0.89638493, 0.8963741 ]),\n",
              "  'split6_test_score': array([0.8277027 , 0.8277027 , 0.82820946, 0.82809685, 0.82809685]),\n",
              "  'split6_train_score': array([0.90741758, 0.90742843, 0.90751518, 0.90748626, 0.90745012]),\n",
              "  'split7_test_score': array([0.8860221 , 0.8861326 , 0.88679558, 0.88668508, 0.88657459]),\n",
              "  'split7_train_score': array([0.89511707, 0.8951098 , 0.89492074, 0.89488074, 0.89483711]),\n",
              "  'split8_test_score': array([0.90030012, 0.90006002, 0.89861945, 0.89861945, 0.89855942]),\n",
              "  'split8_train_score': array([0.89327993, 0.89327637, 0.89331197, 0.89325857, 0.89324077]),\n",
              "  'split9_test_score': array([0.85261059, 0.85255016, 0.85267102, 0.85267102, 0.85273145]),\n",
              "  'split9_train_score': array([0.90269797, 0.90272997, 0.90256286, 0.90250242, 0.90247753]),\n",
              "  'std_fit_time': array([0.01717614, 0.02662834, 0.00736194, 0.03341838, 0.06630841]),\n",
              "  'std_score_time': array([0.00186855, 0.00028391, 0.00039096, 0.00080471, 0.00093918]),\n",
              "  'std_test_score': array([0.02213904, 0.02214079, 0.02200833, 0.02200482, 0.02200489]),\n",
              "  'std_train_score': array([0.00494774, 0.00494782, 0.00492354, 0.00493069, 0.00492905])},\n",
              " 'error_score': nan,\n",
              " 'estimator': LogisticRegression(max_iter=6000),\n",
              " 'feature_names_in_': array(['AGE_ABOVE65', 'AGE_PERCENTIL', 'GENDER', 'DISEASE GROUPING 1',\n",
              "        'DISEASE GROUPING 2', 'DISEASE GROUPING 3', 'DISEASE GROUPING 4',\n",
              "        'DISEASE GROUPING 5', 'DISEASE GROUPING 6', 'HTN',\n",
              "        'IMMUNOCOMPROMISED', 'OTHER', 'ALBUMIN_MEDIAN', 'ALBUMIN_MEAN',\n",
              "        'ALBUMIN_MIN', 'ALBUMIN_MAX', 'ALBUMIN_DIFF', 'BE_ARTERIAL_MEDIAN',\n",
              "        'BE_ARTERIAL_MEAN', 'BE_ARTERIAL_MIN', 'BE_ARTERIAL_MAX',\n",
              "        'BE_ARTERIAL_DIFF', 'BE_VENOUS_MEDIAN', 'BE_VENOUS_MEAN',\n",
              "        'BE_VENOUS_MIN', 'BE_VENOUS_MAX', 'BE_VENOUS_DIFF',\n",
              "        'BIC_ARTERIAL_MEDIAN', 'BIC_ARTERIAL_MEAN', 'BIC_ARTERIAL_MIN',\n",
              "        'BIC_ARTERIAL_MAX', 'BIC_ARTERIAL_DIFF', 'BIC_VENOUS_MEDIAN',\n",
              "        'BIC_VENOUS_MEAN', 'BIC_VENOUS_MIN', 'BIC_VENOUS_MAX',\n",
              "        'BIC_VENOUS_DIFF', 'BILLIRUBIN_MEDIAN', 'BILLIRUBIN_MEAN',\n",
              "        'BILLIRUBIN_MIN', 'BILLIRUBIN_MAX', 'BILLIRUBIN_DIFF',\n",
              "        'BLAST_MEDIAN', 'BLAST_MEAN', 'BLAST_MIN', 'BLAST_MAX',\n",
              "        'BLAST_DIFF', 'CALCIUM_MEDIAN', 'CALCIUM_MEAN', 'CALCIUM_MIN',\n",
              "        'CALCIUM_MAX', 'CALCIUM_DIFF', 'CREATININ_MEDIAN',\n",
              "        'CREATININ_MEAN', 'CREATININ_MIN', 'CREATININ_MAX',\n",
              "        'CREATININ_DIFF', 'FFA_MEDIAN', 'FFA_MEAN', 'FFA_MIN', 'FFA_MAX',\n",
              "        'FFA_DIFF', 'GGT_MEDIAN', 'GGT_MEAN', 'GGT_MIN', 'GGT_MAX',\n",
              "        'GGT_DIFF', 'GLUCOSE_MEDIAN', 'GLUCOSE_MEAN', 'GLUCOSE_MIN',\n",
              "        'GLUCOSE_MAX', 'GLUCOSE_DIFF', 'HEMATOCRITE_MEDIAN',\n",
              "        'HEMATOCRITE_MEAN', 'HEMATOCRITE_MIN', 'HEMATOCRITE_MAX',\n",
              "        'HEMATOCRITE_DIFF', 'HEMOGLOBIN_MEDIAN', 'HEMOGLOBIN_MEAN',\n",
              "        'HEMOGLOBIN_MIN', 'HEMOGLOBIN_MAX', 'HEMOGLOBIN_DIFF',\n",
              "        'INR_MEDIAN', 'INR_MEAN', 'INR_MIN', 'INR_MAX', 'INR_DIFF',\n",
              "        'LACTATE_MEDIAN', 'LACTATE_MEAN', 'LACTATE_MIN', 'LACTATE_MAX',\n",
              "        'LACTATE_DIFF', 'LEUKOCYTES_MEDIAN', 'LEUKOCYTES_MEAN',\n",
              "        'LEUKOCYTES_MIN', 'LEUKOCYTES_MAX', 'LEUKOCYTES_DIFF',\n",
              "        'LINFOCITOS_MEDIAN', 'LINFOCITOS_MEAN', 'LINFOCITOS_MIN',\n",
              "        'LINFOCITOS_MAX', 'LINFOCITOS_DIFF', 'NEUTROPHILES_MEDIAN',\n",
              "        'NEUTROPHILES_MEAN', 'NEUTROPHILES_MIN', 'NEUTROPHILES_MAX',\n",
              "        'NEUTROPHILES_DIFF', 'P02_ARTERIAL_MEDIAN', 'P02_ARTERIAL_MEAN',\n",
              "        'P02_ARTERIAL_MIN', 'P02_ARTERIAL_MAX', 'P02_ARTERIAL_DIFF',\n",
              "        'P02_VENOUS_MEDIAN', 'P02_VENOUS_MEAN', 'P02_VENOUS_MIN',\n",
              "        'P02_VENOUS_MAX', 'P02_VENOUS_DIFF', 'PC02_ARTERIAL_MEDIAN',\n",
              "        'PC02_ARTERIAL_MEAN', 'PC02_ARTERIAL_MIN', 'PC02_ARTERIAL_MAX',\n",
              "        'PC02_ARTERIAL_DIFF', 'PC02_VENOUS_MEDIAN', 'PC02_VENOUS_MEAN',\n",
              "        'PC02_VENOUS_MIN', 'PC02_VENOUS_MAX', 'PC02_VENOUS_DIFF',\n",
              "        'PCR_MEDIAN', 'PCR_MEAN', 'PCR_MIN', 'PCR_MAX', 'PCR_DIFF',\n",
              "        'PH_ARTERIAL_MEDIAN', 'PH_ARTERIAL_MEAN', 'PH_ARTERIAL_MIN',\n",
              "        'PH_ARTERIAL_MAX', 'PH_ARTERIAL_DIFF', 'PH_VENOUS_MEDIAN',\n",
              "        'PH_VENOUS_MEAN', 'PH_VENOUS_MIN', 'PH_VENOUS_MAX',\n",
              "        'PH_VENOUS_DIFF', 'PLATELETS_MEDIAN', 'PLATELETS_MEAN',\n",
              "        'PLATELETS_MIN', 'PLATELETS_MAX', 'PLATELETS_DIFF',\n",
              "        'POTASSIUM_MEDIAN', 'POTASSIUM_MEAN', 'POTASSIUM_MIN',\n",
              "        'POTASSIUM_MAX', 'POTASSIUM_DIFF', 'SAT02_ARTERIAL_MEDIAN',\n",
              "        'SAT02_ARTERIAL_MEAN', 'SAT02_ARTERIAL_MIN', 'SAT02_ARTERIAL_MAX',\n",
              "        'SAT02_ARTERIAL_DIFF', 'SAT02_VENOUS_MEDIAN', 'SAT02_VENOUS_MEAN',\n",
              "        'SAT02_VENOUS_MIN', 'SAT02_VENOUS_MAX', 'SAT02_VENOUS_DIFF',\n",
              "        'SODIUM_MEDIAN', 'SODIUM_MEAN', 'SODIUM_MIN', 'SODIUM_MAX',\n",
              "        'SODIUM_DIFF', 'TGO_MEDIAN', 'TGO_MEAN', 'TGO_MIN', 'TGO_MAX',\n",
              "        'TGO_DIFF', 'TGP_MEDIAN', 'TGP_MEAN', 'TGP_MIN', 'TGP_MAX',\n",
              "        'TGP_DIFF', 'TTPA_MEDIAN', 'TTPA_MEAN', 'TTPA_MIN', 'TTPA_MAX',\n",
              "        'TTPA_DIFF', 'UREA_MEDIAN', 'UREA_MEAN', 'UREA_MIN', 'UREA_MAX',\n",
              "        'UREA_DIFF', 'DIMER_MEDIAN', 'DIMER_MEAN', 'DIMER_MIN',\n",
              "        'DIMER_MAX', 'DIMER_DIFF', 'BLOODPRESSURE_DIASTOLIC_MEAN',\n",
              "        'BLOODPRESSURE_SISTOLIC_MEAN', 'HEART_RATE_MEAN',\n",
              "        'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN',\n",
              "        'OXYGEN_SATURATION_MEAN', 'BLOODPRESSURE_DIASTOLIC_MEDIAN',\n",
              "        'BLOODPRESSURE_SISTOLIC_MEDIAN', 'HEART_RATE_MEDIAN',\n",
              "        'RESPIRATORY_RATE_MEDIAN', 'TEMPERATURE_MEDIAN',\n",
              "        'OXYGEN_SATURATION_MEDIAN', 'BLOODPRESSURE_DIASTOLIC_MIN',\n",
              "        'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN',\n",
              "        'RESPIRATORY_RATE_MIN', 'TEMPERATURE_MIN', 'OXYGEN_SATURATION_MIN',\n",
              "        'BLOODPRESSURE_DIASTOLIC_MAX', 'BLOODPRESSURE_SISTOLIC_MAX',\n",
              "        'HEART_RATE_MAX', 'RESPIRATORY_RATE_MAX', 'TEMPERATURE_MAX',\n",
              "        'OXYGEN_SATURATION_MAX', 'BLOODPRESSURE_DIASTOLIC_DIFF',\n",
              "        'BLOODPRESSURE_SISTOLIC_DIFF', 'HEART_RATE_DIFF',\n",
              "        'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF',\n",
              "        'OXYGEN_SATURATION_DIFF', 'BLOODPRESSURE_DIASTOLIC_DIFF_REL',\n",
              "        'BLOODPRESSURE_SISTOLIC_DIFF_REL', 'HEART_RATE_DIFF_REL',\n",
              "        'RESPIRATORY_RATE_DIFF_REL', 'TEMPERATURE_DIFF_REL',\n",
              "        'OXYGEN_SATURATION_DIFF_REL'], dtype=object),\n",
              " 'multimetric_': False,\n",
              " 'n_jobs': None,\n",
              " 'n_splits_': 50,\n",
              " 'param_grid': {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
              " 'pre_dispatch': '2*n_jobs',\n",
              " 'refit': True,\n",
              " 'refit_time_': 0.34186577796936035,\n",
              " 'return_train_score': True,\n",
              " 'scorer_': make_scorer(roc_auc_score, needs_threshold=True),\n",
              " 'scoring': 'roc_auc',\n",
              " 'verbose': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x=[]\n",
        "for item in resultados.cv_results_['params']:\n",
        "  x.append(item['solver'])\n",
        "plt.plot(x, resultados.cv_results_['mean_test_score'], color='orange')\n",
        "plt.plot(x, resultados.cv_results_['mean_train_score'], color='blue')"
      ],
      "metadata": {
        "id": "4Kqb9hWknQ7U",
        "outputId": "19aeec70-b866-4134-cb04-659d7ea2659b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faf95ebc890>]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWcElEQVR4nO3df7RdZX3n8fcnNwkBFKxNdCkBiS0zQzosqRzRWn+gLCymVpxpraSg0mFJpxamw2DX4Co6LGa65oedtRwtUKEDWFrBqFUzHYQiwmgFa27kV4iiaayQwNTr+AP8CUm+88fZkcPlJvfc3HNzkzzv11pnnec8+9nPfvbOOeezf52bVBWSpPYsmO8BSJLmhwEgSY0yACSpUQaAJDXKAJCkRhkAktSooQIgyalJ7k+yKcmFU0x/XpJbktyT5LYkywemvTXJ17rHWwfqT0hyb9fn+5JkNKskSRpGpvsdQJIx4KvAKcAWYB2wuqo2DrT5CPDXVfXBJK8Gfruq3pzkmcA40AMKWA+cUFXfSfJF4N8AfwfcALyvqj418jWUJE1p4RBtTgQ2VdVmgCTXA6cBGwfarAT+XVe+FfhEV/4V4Oaq+nY3783AqUluAw6rqi909X8OvAHYbQAsXbq0jj766CGGLEnaaf369d+qqmWT64cJgCOABwdebwFePKnN3cC/BP4H8C+Apyf52V3Me0T32DJF/VMkOQc4B+Coo45ifHx8iCFLknZK8o2p6kd1EfgdwCuT3Am8EtgKbB9Fx1V1RVX1qqq3bNlTAkyStIeGOQLYChw58Hp5V/dTVfUQ/SMAkjwN+PWq+m6SrcBJk+a9rZt/+aT6J/UpSZpbwxwBrAOOSbIiyWLgdGDtYIMkS5Ps7OudwFVd+SbgNUl+JsnPAK8Bbqqqh4FHkryku/vnLcAnR7A+kqQhTRsAVbUNOJf+l/mXgTVVdV+SS5K8vmt2EnB/kq8Czwb+qJv328B/pB8i64BLdl4QBt4O/BmwCfh7prkALEkarWlvA92X9Hq98iKwJM1MkvVV1Ztc7y+BJalRBoAkNWqYu4D2e+9/P0xMTN9u2D9GMUy7UfY1H8tcsAAWLeo/Fi6cu/LY2PDjljRaTQTABz4AGzfuvs1+dCnkgDOXAbO3yoNBtqvn3U2bSZtR9zfdNB24mgiADRv27vKGDZNRthv1Mrdvh8cfh23b+s/7YvlHP5r5vNpzcxFewzxm0nY28+zNZe3JPB/+MCxePPt/x0FNBMDeNurTP/Nh0SJYsmS+RzFaVXMXbNu3P7GMqZ53N21P2u5rbfakv2EeM2k72/nmap4dO0a3nFEzANSMpH+6ZqHvegnwLiBJapYBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjhgqAJKcmuT/JpiQXTjH9qCS3JrkzyT1JVnX1i5NcneTeJHcnOWlgntu6Pu/qHs8a2VpJkqa1cLoGScaAS4FTgC3AuiRrq2rjQLOLgDVVdXmSlcANwNHA2wCq6rjuC/5TSV5UVTu6+c6oqvHRrY4kaVjDHAGcCGyqqs1V9RhwPXDapDYFHNaVDwce6sorgc8AVNU3ge8CvdkOWpI0e8MEwBHAgwOvt3R1gy4Gzkyyhf7e/3ld/d3A65MsTLICOAE4cmC+q7vTP+9KkqkWnuScJONJxicmJoYYriRpGKO6CLwauKaqlgOrgGuTLACuoh8Y48B7gduB7d08Z1TVccDLu8ebp+q4qq6oql5V9ZYtWzai4UqShgmArTx5r315VzfobGANQFXdASwBllbVtqo6v6qOr6rTgGcAX+3abe2eHwU+RP9UkyRpLxkmANYBxyRZkWQxcDqwdlKbB4CTAZIcSz8AJpIckuTQrv4UYFtVbexOCS3t6hcBrwM2jGSNJElDmfYuoKraluRc4CZgDLiqqu5LcgkwXlVrgQuAK5OcT/+C8FlVVd2dPzcl2UH/qGHnaZ6DuvpFXZ+fBq4c9cpJknYtVTXfYxhar9er8XHvGpWkmUiyvqqecgemvwSWpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRQwVAklOT3J9kU5ILp5h+VJJbk9yZ5J4kq7r6xUmuTnJvkruTnDQwzwld/aYk70uSka2VJGla0wZAkjHgUuC1wEpgdZKVk5pdBKypql8ETgcu6+rfBlBVxwGnAP89yc5lXt5NP6Z7nDq7VZEkzcQwRwAnApuqanNVPQZcD5w2qU0Bh3Xlw4GHuvJK4DMAVfVN4LtAL8lzgMOq6gtVVcCfA2+Y1ZpIkmZkmAA4Anhw4PWWrm7QxcCZSbYANwDndfV3A69PsjDJCuAE4Mhu/i3T9AlAknOSjCcZn5iYGGK4kqRhjOoi8GrgmqpaDqwCru1O9VxF/8t9HHgvcDuwfSYdV9UVVdWrqt6yZctGNFxJ0sIh2mylv9e+0/KubtDZdOfwq+qOJEuApd1pn/N3NkpyO/BV4DtdP7vrU5I0h4Y5AlgHHJNkRZLF9C/yrp3U5gHgZIAkxwJLgIkkhyQ5tKs/BdhWVRur6mHgkSQv6e7+eQvwydGskiRpGNMeAVTVtiTnAjcBY8BVVXVfkkuA8apaC1wAXJnkfPoXhM+qqkryLOCmJDvo7+G/eaDrtwPXAAcDn+oekqS9JP2bcPYPvV6vxsfH53sYkrRfSbK+qnqT6/0lsCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWrUUAGQ5NQk9yfZlOTCKaYfleTWJHcmuSfJqq5+UZIPJrk3yZeTvHNgnn/o6u9KMj66VZIkDWPhdA2SjAGXAqcAW4B1SdZW1caBZhcBa6rq8iQrgRuAo4E3AgdV1XFJDgE2Jrmuqv6hm+9VVfWt0a2OJGlYwxwBnAhsqqrNVfUYcD1w2qQ2BRzWlQ8HHhqoPzTJQuBg4DHgkVmPWpI0a8MEwBHAgwOvt3R1gy4Gzkyyhf7e/3ld/UeBHwAPAw8Af1xV3+6mFfA3SdYnOWfPhi9J2lOjugi8GrimqpYDq4Brkyygf/SwHXgusAK4IMnzu3leVlUvBF4L/F6SV0zVcZJzkownGZ+YmBjRcCVJwwTAVuDIgdfLu7pBZwNrAKrqDmAJsBT4LeDGqnq8qr4JfB7ode22ds/fBD5OPyyeoqquqKpeVfWWLVs27HpJkqYxTACsA45JsiLJYuB0YO2kNg8AJwMkOZZ+AEx09a/u6g8FXgJ8JcmhSZ4+UP8aYMPsV0eSNKxp7wKqqm1JzgVuAsaAq6rqviSXAONVtRa4ALgyyfn0z+2fVVWV5FLg6iT3AQGurqp7utNAH0+ycwwfqqob52QNJUlTSlXN9xiG1uv1anzcnwxI0kwkWV9Vvcn1/hJYkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGDRUASU5Ncn+STUkunGL6UUluTXJnknuSrOrqFyX5YJJ7k3w5yTuH7VOSNLemDYAkY8ClwGuBlcDqJCsnNbsIWFNVvwicDlzW1b8ROKiqjgNOAH4nydFD9ilJmkPDHAGcCGyqqs1V9RhwPXDapDYFHNaVDwceGqg/NMlC4GDgMeCRIfuUJM2hYQLgCODBgddburpBFwNnJtkC3ACc19V/FPgB8DDwAPDHVfXtIfsEIMk5ScaTjE9MTAwxXEnSMEZ1EXg1cE1VLQdWAdcmWUB/T3878FxgBXBBkufPpOOquqKqelXVW7Zs2YiGK0laOESbrcCRA6+Xd3WDzgZOBaiqO5IsAZYCvwXcWFWPA99M8nmgR3/vf7o+JUlzaJgjgHXAMUlWJFlM/yLv2kltHgBOBkhyLLAEmOjqX93VHwq8BPjKkH1KkubQtAFQVduAc4GbgC/Tv9vnviSXJHl91+wC4G1J7gauA86qqqJ/p8/TktxH/0v/6qq6Z1d9jnrlJEm7lv739P6h1+vV+Pj4fA9DkvYrSdZXVW9yvb8ElqRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUUMFQJJTk9yfZFOSC6eYflSSW5PcmeSeJKu6+jOS3DXw2JHk+G7abV2fO6c9a7SrJknanYXTNUgyBlwKnAJsAdYlWVtVGweaXQSsqarLk6wEbgCOrqq/BP6y6+c44BNVddfAfGdU1fiI1kWSNAPDHAGcCGyqqs1V9RhwPXDapDYFHNaVDwcemqKf1d28kqR9wDABcATw4MDrLV3doIuBM5Nsob/3f94U/bwJuG5S3dXd6Z93JclUC09yTpLxJOMTExNDDFeSNIxRXQReDVxTVcuBVcC1SX7ad5IXAz+sqg0D85xRVccBL+8eb56q46q6oqp6VdVbtmzZiIYrSRomALYCRw68Xt7VDTobWANQVXcAS4ClA9NPZ9Lef1Vt7Z4fBT5E/1STJGkvGSYA1gHHJFmRZDH9L/O1k9o8AJwMkORY+gEw0b1eAPwmA+f/kyxMsrQrLwJeB2xAkrTXTHsXUFVtS3IucBMwBlxVVfcluQQYr6q1wAXAlUnOp39B+Kyqqq6LVwAPVtXmgW4PAm7qvvzHgE8DV45srSRJ08oT39P7vl6vV+Pje3DX6Prz4YcPTt9OT8gCWLAYFizqnhdDFsHYkOV08820vGARTH0/gKQ9lGR9VfUm1097BHBA+P5m+P7fz/co9i+1HXY8DjseG3jeWf7J3C47C58InQWLnhpEIy+PoI/4o3rtf9oIgFd+cr5HcGCpmhQQU4XE7soDdfU4bJ9FecdP4PFHu/I0y67tc7xhdnPkMu1Rze6mTzPvvPU9m+UO9j3YLlMsd4p2U837lLpp2s9mWXM17+76e+2dMHYQo9RGAGi0km4vfSFw8HyPZng7tndBsYdhtdtw2bbr5U57mnV306eZd976ns1yB/uu3dftLNcUdbudd676nWbeUff3pHajPzVqAKgdC8aAMRhbMt8jkfYJnriUpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNWq/+mNwSSaAb+zh7EuBb41wOAc6t9fMuL1mxu01M7PdXs+rqqf8j1r7VQDMRpLxqf4anqbm9poZt9fMuL1mZq62l6eAJKlRBoAkNaqlALhivgewn3F7zYzba2bcXjMzJ9urmWsAkqQna+kIQJI0wACQpEYdkAGQ5KQkL53vcexrkny/ez4pyV/vos0bk3w5ya17d3R738D2eG6Sj3bls5L8ybDtpf3ZARkAwEmAAbBnzgbeVlWvmu+B7C1V9VBV/cZctd8TSfzf+jTn9okASHJ0t9d5ZZL7kvxNkoOT/FySG5OsT/K5JP8syViSr6fvGUm2J3lF189nkxwD/Gvg/CR3JXl51/9nktyT5JYkR3Xtr0nyviS3J9mcZMoPdZJnJ/l4kru7x0u7+ncluT/J3ya5Lsk79tY2G4HDkvzvbvx/mmRBkncDLwP+Z5L3JDkkyZokG7v1/7skve7f4JokG5Lcm+T8+V6Z2ejeHxsGqo5McluSryX5D7tr3x0x/FX3Pv1akv820O41Se5I8qUkH0nytK7+3UnWddvviqT/P4F3y3xvknHg9+d2redWkkO799fd3Xq+aTfr/aLus3lX977bMF3/B4JRbKPuvfi57j32pcz0zEdVzfsDOBrYBhzfvV4DnAncAhzT1b0Y+ExXvhH4BeB1wDrgD4GDgK930y8G3jHQ//8C3tqV/xXwia58DfAR+kG4Eti0i/F9GPi3XXkMOBx4EXAXsAR4OvC1wWXuiw/g+93zScCPged363Mz8BvdtNuAXld+B/CBrvzPu3+jHnACcPNAv8+Y73Wb5fY4GtjQlc8CHgZ+lv7/eL9hYHvsqv3m7j2xhP6fKjmS/k/3Pwsc2rX798C7u/IzB8ZwLfBrA9v+svneLiPatr8OXDnw+vDdrPcG4Je68n/ZuW0P9McothFwCLCkKx8DjM9kDPvEEUDn61V1V1deT/9D9lLgI0nuAj4APKeb/jngFd3jP9Pfa30R/TCYyi8BH+rK13btd/pEVe2oqo3As3cx/6uBywGqantVfQ/4ZeCTVfXjqnqUfsjsT75YVZurajtwHU/eJju9DLgeoKo2APd09ZuB5yd5f5JTgUf2xoD3opur6v9V1Y+Av2LqbTPolqr6XlX9GNgIPA94Cf2dis9379+3dvUAr+qOpu6l/976hYG+PjzKFZlH9wKnJPmvSV7efWaest5JngE8varu6Ob70K46PACNYhstAq7s2n+E/ntuaPvSecafDJS30/8y/m5VHT9F288Cvws8F3g38Af092o/N8vl7jzc+iPgVwF2sfwDweQfgAz9g5Cq+k6SFwC/Qv9022/SP7I6UMx020x+7y6k/166uapWDzZMsgS4jP5RxYNJLqZ/5LDTD/ZoxPuYqvpqkhcCq4D/lOQW4PfY9Xo3Z0Tb6HzgH4EX0D+T8eOZjGFfOgKY7BHg60neCJC+F3TTvkj/6GBHt9d1F/A79IMB4FH6p2V2uh04vSufwTRBUVV/WFXHD3z530I/cOjOfx8OfB74tSRLunO7r9vzVZ0XJyZZkWQB8Cbgb6do83n6X+4kWQkc15WXAguq6mPARcAL986Q95pTkjwzycHAG+hvh5n6AvDLSX4efnq+95/wxAf6W937Zk4vJs+XJM8FflhVfwG8hyfeI09a76r6LvBokhd3009/SmcHqBFto8OBh6tqB/Bm+qd0h7YvHQFM5Qzg8iQX0T/UuR64u6p+kuRB+h8y6H+hr6Z/SAX90zEfTXIacF73uDrJHwATwG/PcBy/D1yR5Gz6e3i/W1V3JFlL/7TIP3bL/t4erud8WAf8CfDzwK3Ax6docxnwwSQbga8A99FfxyPob8+dOxDvnPvh7lVfBD4GLAf+oqrGZ9pBVU0kOQu4LslBXfVF3V7flfTP6f5fdn3acn93HPCeJDuAx+nvQL2Bqdf7bPqnMXYA/4f963M0G6PYRpcBH0vyFvrXRmd0BOmfgpiFJE+rqu8nOYT+0cc5VfWl+R7XqCQZAxZV1Y+T/BzwaeCfVtVj8zw0HUB2fo668oXAc6pqv74LatTmahvt60cA+7orulMjS4APHkhf/p1DgFuTLKJ/TvvtfvlrDvxqknfS/z76Bv07q/Rkc7KNPAKQpEbtyxeBJUlzyACQpEYZAJLUKANAkhplAEhSo/4/dU6Se4h9wfIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GklBsMLe3tBr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}