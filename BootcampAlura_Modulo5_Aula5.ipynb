{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "BootcampAlura_Modulo4.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-01-13T01:35:57.085222Z",
          "iopub.execute_input": "2022-01-13T01:35:57.085816Z",
          "iopub.status.idle": "2022-01-13T01:35:57.095345Z",
          "shell.execute_reply.started": "2022-01-13T01:35:57.085774Z",
          "shell.execute_reply": "2022-01-13T01:35:57.094402Z"
        },
        "trusted": true,
        "id": "11dHHrocMEV-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_excel(\"https://github.com/alura-cursos/covid-19-clinical/blob/main/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T01:36:05.490938Z",
          "iopub.execute_input": "2022-01-13T01:36:05.491168Z",
          "iopub.status.idle": "2022-01-13T01:36:10.015146Z",
          "shell.execute_reply.started": "2022-01-13T01:36:05.491141Z",
          "shell.execute_reply": "2022-01-13T01:36:10.014208Z"
        },
        "trusted": true,
        "id": "BXTyDNXFMEWA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tratamento da Base 1\")\n",
        "\n",
        "pacientes_UTI = dados[['PATIENT_VISIT_IDENTIFIER','ICU']].query('ICU == 1').groupby('PATIENT_VISIT_IDENTIFIER').min()\n",
        "dados_tratados = dados.query('ICU != 1').drop('ICU', axis=1)\n",
        "dados_tratados = dados_tratados.join(pacientes_UTI, on='PATIENT_VISIT_IDENTIFIER', how='left')\n",
        "dados_tratados['ICU'] = dados_tratados['ICU'].fillna(0) \n",
        "print(\"\\nRemovemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\")\n",
        "print(f\"Distribuição de ICU na base tratada (%)\\n{dados_tratados['ICU'].value_counts(normalize=True)*100}\")\n",
        "\n",
        "features_continuas_colunas = dados_tratados.iloc[:, 13:-2].columns\n",
        "features_continuas = dados_tratados.groupby(\"PATIENT_VISIT_IDENTIFIER\",as_index=False)[features_continuas_colunas].fillna(method='bfill').fillna(method='ffill')\n",
        "features_categoricas = dados_tratados.iloc[:, :13]\n",
        "saida = dados_tratados.iloc[:, -2:]\n",
        "dados_tratados = pd.concat([features_categoricas, features_continuas, saida], ignore_index=True,axis=1)\n",
        "dados_tratados.columns = dados.columns\n",
        "print(\"\\nAjustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\")\n",
        "\n",
        "descricao = dados_tratados.describe().T\n",
        "colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "if len(colunas_sem_variacao) !=0:\n",
        "  dados_tratados.drop(colunas_sem_variacao, axis=1)\n",
        "  print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "colunas_categoricas = list(set(dados_tratados.columns)-set(dados_tratados.describe().columns)-{'WINDOW'})\n",
        "colunas_categoricas\n",
        "if len(colunas_categoricas) ==1:\n",
        "  LE = preprocessing.LabelEncoder()\n",
        "  LE.fit(np.ravel(dados_tratados[colunas_categoricas]))\n",
        "  dados_tratados[colunas_categoricas] = LE.transform(np.ravel(dados_tratados[colunas_categoricas]))\n",
        "  print(f\"\\nColuna com objeto categórico ({colunas_categoricas[0]}) foi transformada em numérica\")\n",
        "else:\n",
        "  print(f\"\\nColunas com objetos categóricos precisam ser tratados: {', '.join(colunas_categoricas)}\")\n",
        "\n",
        "\n",
        "linhas_com_nam = dados_tratados.describe(include='all').loc['count'].max()-dados_tratados.describe(include='all').loc['count'].min()\n",
        "if linhas_com_nam !=0:\n",
        "  if linhas_com_nam <= len(dados_tratados)*.1:\n",
        "    dados_tratados.dropna(inplace=True)\n",
        "    print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) foram eliminadas\")\n",
        "  else:\n",
        "    print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) precisam ser tratadas\")\n",
        "\n",
        "dados_tratados.reset_index(drop=True, inplace=True)\n",
        "print(f\"\\nO index foi resetado: {dados_tratados.index}\")\n",
        "\n",
        "print(f\"\\nFormato final do DataFrame dados_tratados: {dados_tratados.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-13T01:36:11.633841Z",
          "iopub.execute_input": "2022-01-13T01:36:11.634513Z",
          "iopub.status.idle": "2022-01-13T01:36:11.703375Z",
          "shell.execute_reply.started": "2022-01-13T01:36:11.634461Z",
          "shell.execute_reply": "2022-01-13T01:36:11.702371Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN4V01nBMEWC",
        "outputId": "54a606a6-6c0a-4c6d-8be8-b32dcf584cbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tratamento da Base 1\n",
            "\n",
            "Removemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\n",
            "Distribuição de ICU na base tratada (%)\n",
            "0.0    67.375887\n",
            "1.0    32.624113\n",
            "Name: ICU, dtype: float64\n",
            "\n",
            "Ajustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\n",
            "\n",
            "Removemos as colunas que os valores são iguais para todas as linhas\n",
            "\n",
            "Coluna com objeto categórico (AGE_PERCENTIL) foi transformada em numérica\n",
            "\n",
            "As linhas ainda com Nam (5.0 linhas, 0.36% do total) foram eliminadas\n",
            "\n",
            "O index foi resetado: RangeIndex(start=0, stop=1405, step=1)\n",
            "\n",
            "Formato final do DataFrame dados_tratados: (1405, 231)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Segunda Base Tratada\")\n",
        "\n",
        "age_percentil = np.array(dados_tratados['AGE_PERCENTIL']).reshape(-1, 1)\n",
        "OHE = preprocessing.OneHotEncoder()\n",
        "age_percentil_OHE = pd.DataFrame(OHE.fit_transform(age_percentil).toarray())\n",
        "dados_tratados_OHE = pd.concat([dados_tratados.drop('AGE_PERCENTIL', axis=1), age_percentil_OHE], ignore_index=True, axis=1)\n",
        "colunas = list(dados_tratados.columns)\n",
        "colunas.remove('AGE_PERCENTIL')\n",
        "colunas_novas = list(dados['AGE_PERCENTIL'].unique())\n",
        "colunas_novas.sort()\n",
        "colunas.extend(colunas_novas)\n",
        "dados_tratados_OHE.columns = colunas\n",
        "print(f\"\\nTrocamos o campo AGE_PERCENTIL pelos campos binários {', '.join(colunas_novas)}\")\n",
        "\n",
        "print(f\"\\nFormato final do DataFrame dados_tratados_OHE: {dados_tratados_OHE.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI0sdLsZSUIk",
        "outputId": "2336b834-3218-4b30-d6f4-c9752cab1348"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segunda Base Tratada\n",
            "\n",
            "Trocamos o campo AGE_PERCENTIL pelos campos binários 10th, 20th, 30th, 40th, 50th, 60th, 70th, 80th, 90th, Above 90th\n",
            "\n",
            "Formato final do DataFrame dados_tratados_OHE: (1405, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def roda_modelo_cv(modelo, dados, n_splits, n_repeats):\n",
        "\n",
        "    np.random.seed(4367)\n",
        "    dados = dados.sample(frac=1).reset_index(drop=True)\n",
        "    y = dados[\"ICU\"]\n",
        "    x = dados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "    \n",
        "    \n",
        "    cv = RepeatedKFold(n_splits = n_splits, n_repeats=n_repeats)\n",
        "    resultados=cross_validate(modelo, x, y, cv=cv, scoring='roc_auc')\n",
        "    \n",
        "    auc_medio = np.mean(resultados['test_score'])\n",
        "    auc_std = np.std(resultados['test_score'])\n",
        "    \n",
        " \n",
        "    print(f\"AUC Médio {auc_medio} Intervalo {auc_medio - (2*auc_std)} - {auc_medio + (2*auc_std)}\")"
      ],
      "metadata": {
        "id": "9hO_3WQpbqMA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roda_modelo_stratified_cv(modelo, dados, n_splits, n_repeats):\n",
        "\n",
        "    np.random.seed(4367)\n",
        "    dados = dados.sample(frac=1).reset_index(drop=True)\n",
        "    y = dados[\"ICU\"]\n",
        "    x = dados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "    \n",
        "    \n",
        "    cv = RepeatedStratifiedKFold(n_splits = n_splits, n_repeats=n_repeats)\n",
        "    resultados=cross_validate(modelo, x, y, cv=cv, scoring='roc_auc')\n",
        "    \n",
        "    auc_medio = np.mean(resultados['test_score'])\n",
        "    auc_std = np.std(resultados['test_score'])\n",
        "    \n",
        " \n",
        "    print(f\"AUC Médio {auc_medio} Intervalo {auc_medio - (2*auc_std)} - {auc_medio + (2*auc_std)}\")"
      ],
      "metadata": {
        "id": "jmASe-VEOIVr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roda_modelo_cv(LogisticRegression(max_iter=9000),dados_tratados.query('WINDOW == \"0-2\"'),5,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLyJ_AJdL-Cb",
        "outputId": "46fd760c-f576-4666-e9b2-d198ae0aeb30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Médio 0.7585856878805273 Intervalo 0.6728163048854148 - 0.8443550708756398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roda_modelo_stratified_cv(LogisticRegression(max_iter=9000),dados_tratados.query('WINDOW == \"0-2\"'),5,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHhPeaMZMdK8",
        "outputId": "e219aaef-9361-40e0-e2d6-e8e77f152f45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Médio 0.7571566931764301 Intervalo 0.6521306135217886 - 0.8621827728310716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados_tratados.query('WINDOW == \"0-2\"').ICU.value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8jYxCb_MvPD",
        "outputId": "2fe2bc56-e3e4-4ab1-b82b-360b66c5fd81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    0.536932\n",
              "1.0    0.463068\n",
              "Name: ICU, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class modelos:\n",
        "  def __init__(self, a, b, **kwargs):\n",
        "    self.a = a\n",
        "    self.b = b\n",
        "  def metodo_a (self, c):\n",
        "    return self.a*self.b*c"
      ],
      "metadata": {
        "id": "ITT3UWkJQOPC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = modelos(10,2)"
      ],
      "metadata": {
        "id": "QXrdEHc6B5gx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.metodo_a(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9Hg47j-B8w6",
        "outputId": "7f70671f-85fc-4a75-c1f8-4e96c6d127dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(LogisticRegression)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud3nDvAICAI6",
        "outputId": "d6778bcf-4d08-437e-9a5c-dcb94d514db1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class LogisticRegression in module sklearn.linear_model._logistic:\n",
            "\n",
            "class LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
            " |  LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
            " |  \n",
            " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
            " |  \n",
            " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
            " |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
            " |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
            " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
            " |  'sag', 'saga' and 'newton-cg' solvers.)\n",
            " |  \n",
            " |  This class implements regularized logistic regression using the\n",
            " |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
            " |  that regularization is applied by default**. It can handle both dense\n",
            " |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
            " |  floats for optimal performance; any other input format will be converted\n",
            " |  (and copied).\n",
            " |  \n",
            " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
            " |  with primal formulation, or no regularization. The 'liblinear' solver\n",
            " |  supports both L1 and L2 regularization, with a dual formulation only for\n",
            " |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
            " |  'saga' solver.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\n",
            " |      Specify the norm of the penalty:\n",
            " |  \n",
            " |      - `'none'`: no penalty is added;\n",
            " |      - `'l2'`: add a L2 penalty term and it is the default choice;\n",
            " |      - `'l1'`: add a L1 penalty term;\n",
            " |      - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
            " |  \n",
            " |      .. warning::\n",
            " |         Some penalties may not work with some solvers. See the parameter\n",
            " |         `solver` below, to know the compatibility between the penalty and\n",
            " |         solver.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
            " |  \n",
            " |  dual : bool, default=False\n",
            " |      Dual or primal formulation. Dual formulation is only implemented for\n",
            " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
            " |      n_samples > n_features.\n",
            " |  \n",
            " |  tol : float, default=1e-4\n",
            " |      Tolerance for stopping criteria.\n",
            " |  \n",
            " |  C : float, default=1.0\n",
            " |      Inverse of regularization strength; must be a positive float.\n",
            " |      Like in support vector machines, smaller values specify stronger\n",
            " |      regularization.\n",
            " |  \n",
            " |  fit_intercept : bool, default=True\n",
            " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
            " |      added to the decision function.\n",
            " |  \n",
            " |  intercept_scaling : float, default=1\n",
            " |      Useful only when the solver 'liblinear' is used\n",
            " |      and self.fit_intercept is set to True. In this case, x becomes\n",
            " |      [x, self.intercept_scaling],\n",
            " |      i.e. a \"synthetic\" feature with constant value equal to\n",
            " |      intercept_scaling is appended to the instance vector.\n",
            " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
            " |  \n",
            " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
            " |      as all other features.\n",
            " |      To lessen the effect of regularization on synthetic feature weight\n",
            " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
            " |  \n",
            " |  class_weight : dict or 'balanced', default=None\n",
            " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
            " |      If not given, all classes are supposed to have weight one.\n",
            " |  \n",
            " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
            " |      weights inversely proportional to class frequencies in the input data\n",
            " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
            " |  \n",
            " |      Note that these weights will be multiplied with sample_weight (passed\n",
            " |      through the fit method) if sample_weight is specified.\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *class_weight='balanced'*\n",
            " |  \n",
            " |  random_state : int, RandomState instance, default=None\n",
            " |      Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
            " |      data. See :term:`Glossary <random_state>` for details.\n",
            " |  \n",
            " |  solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
            " |  \n",
            " |      Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
            " |      To choose a solver, you might want to consider the following aspects:\n",
            " |  \n",
            " |          - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
            " |            and 'saga' are faster for large ones;\n",
            " |          - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
            " |            'lbfgs' handle multinomial loss;\n",
            " |          - 'liblinear' is limited to one-versus-rest schemes.\n",
            " |  \n",
            " |      .. warning::\n",
            " |         The choice of the algorithm depends on the penalty chosen:\n",
            " |         Supported penalties by solver:\n",
            " |  \n",
            " |         - 'newton-cg'   -   ['l2', 'none']\n",
            " |         - 'lbfgs'       -   ['l2', 'none']\n",
            " |         - 'liblinear'   -   ['l1', 'l2']\n",
            " |         - 'sag'         -   ['l2', 'none']\n",
            " |         - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\n",
            " |  \n",
            " |      .. note::\n",
            " |         'sag' and 'saga' fast convergence is only guaranteed on\n",
            " |         features with approximately the same scale. You can\n",
            " |         preprocess the data with a scaler from :mod:`sklearn.preprocessing`.\n",
            " |  \n",
            " |      .. seealso::\n",
            " |         Refer to the User Guide for more information regarding\n",
            " |         :class:`LogisticRegression` and more specifically the\n",
            " |         `Table <https://scikit-learn.org/dev/modules/linear_model.html#logistic-regression>`_\n",
            " |         summarazing solver/penalty supports.\n",
            " |         <!--\n",
            " |         # noqa: E501\n",
            " |         -->\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         Stochastic Average Gradient descent solver.\n",
            " |      .. versionadded:: 0.19\n",
            " |         SAGA solver.\n",
            " |      .. versionchanged:: 0.22\n",
            " |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
            " |  \n",
            " |  max_iter : int, default=100\n",
            " |      Maximum number of iterations taken for the solvers to converge.\n",
            " |  \n",
            " |  multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
            " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
            " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
            " |      across the entire probability distribution, *even when the data is\n",
            " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
            " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
            " |      and otherwise selects 'multinomial'.\n",
            " |  \n",
            " |      .. versionadded:: 0.18\n",
            " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
            " |      .. versionchanged:: 0.22\n",
            " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
            " |  \n",
            " |  verbose : int, default=0\n",
            " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
            " |      number for verbosity.\n",
            " |  \n",
            " |  warm_start : bool, default=False\n",
            " |      When set to True, reuse the solution of the previous call to fit as\n",
            " |      initialization, otherwise, just erase the previous solution.\n",
            " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      Number of CPU cores used when parallelizing over classes if\n",
            " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
            " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
            " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
            " |      context. ``-1`` means using all processors.\n",
            " |      See :term:`Glossary <n_jobs>` for more details.\n",
            " |  \n",
            " |  l1_ratio : float, default=None\n",
            " |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
            " |      used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
            " |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
            " |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
            " |      combination of L1 and L2.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  \n",
            " |  classes_ : ndarray of shape (n_classes, )\n",
            " |      A list of class labels known to the classifier.\n",
            " |  \n",
            " |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
            " |      Coefficient of the features in the decision function.\n",
            " |  \n",
            " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
            " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
            " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
            " |  \n",
            " |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
            " |      Intercept (a.k.a. bias) added to the decision function.\n",
            " |  \n",
            " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
            " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
            " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
            " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
            " |      outcome 0 (False).\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
            " |      Actual number of iterations for all classes. If binary or multinomial,\n",
            " |      it returns only 1 element. For liblinear solver, only the maximum\n",
            " |      number of iteration across all classes is given.\n",
            " |  \n",
            " |      .. versionchanged:: 0.20\n",
            " |  \n",
            " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
            " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  SGDClassifier : Incrementally trained logistic regression (when given\n",
            " |      the parameter ``loss=\"log\"``).\n",
            " |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The underlying C implementation uses a random number generator to\n",
            " |  select features when fitting the model. It is thus not uncommon,\n",
            " |  to have slightly different results for the same input data. If\n",
            " |  that happens, try with a smaller tol parameter.\n",
            " |  \n",
            " |  Predict output may not match that of standalone liblinear in certain\n",
            " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
            " |  in the narrative documentation.\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  \n",
            " |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
            " |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
            " |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
            " |  \n",
            " |  LIBLINEAR -- A Library for Large Linear Classification\n",
            " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
            " |  \n",
            " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
            " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
            " |      https://hal.inria.fr/hal-00860051/document\n",
            " |  \n",
            " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
            " |      SAGA: A Fast Incremental Gradient Method With Support\n",
            " |      for Non-Strongly Convex Composite Objectives\n",
            " |      https://arxiv.org/abs/1407.0202\n",
            " |  \n",
            " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
            " |      methods for logistic regression and maximum entropy models.\n",
            " |      Machine Learning 85(1-2):41-75.\n",
            " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.datasets import load_iris\n",
            " |  >>> from sklearn.linear_model import LogisticRegression\n",
            " |  >>> X, y = load_iris(return_X_y=True)\n",
            " |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
            " |  >>> clf.predict(X[:2, :])\n",
            " |  array([0, 0])\n",
            " |  >>> clf.predict_proba(X[:2, :])\n",
            " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
            " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
            " |  >>> clf.score(X, y)\n",
            " |  0.97...\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      LogisticRegression\n",
            " |      sklearn.linear_model._base.LinearClassifierMixin\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      sklearn.linear_model._base.SparseCoefMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None)\n",
            " |      Fit the model according to the given training data.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          Training vector, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,)\n",
            " |          Target vector relative to X.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,) default=None\n",
            " |          Array of weights that are assigned to individual samples.\n",
            " |          If not provided, then each sample is given unit weight.\n",
            " |      \n",
            " |          .. versionadded:: 0.17\n",
            " |             *sample_weight* support to LogisticRegression.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |          Fitted estimator.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      The SAGA solver supports both float64 and float32 bit arrays.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Predict logarithm of probability estimates.\n",
            " |      \n",
            " |      The returned estimates for all classes are ordered by the\n",
            " |      label of classes.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Vector to be scored, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      T : array-like of shape (n_samples, n_classes)\n",
            " |          Returns the log-probability of the sample for each class in the\n",
            " |          model, where classes are ordered as they are in ``self.classes_``.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Probability estimates.\n",
            " |      \n",
            " |      The returned estimates for all classes are ordered by the\n",
            " |      label of classes.\n",
            " |      \n",
            " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
            " |      the softmax function is used to find the predicted probability of\n",
            " |      each class.\n",
            " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
            " |      of each class assuming it to be positive using the logistic function.\n",
            " |      and normalize these values across all the classes.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Vector to be scored, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      T : array-like of shape (n_samples, n_classes)\n",
            " |          Returns the probability of the sample for each class in the model,\n",
            " |          where classes are ordered as they are in ``self.classes_``.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Predict confidence scores for samples.\n",
            " |      \n",
            " |      The confidence score for a sample is proportional to the signed\n",
            " |      distance of that sample to the hyperplane.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The data matrix for which we want to get the confidence scores.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
            " |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
            " |          this class would be predicted.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict class labels for samples in X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The data matrix for which we want to get the predictions.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,)\n",
            " |          Vector containing the class labels for each sample.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
            " |  \n",
            " |  densify(self)\n",
            " |      Convert coefficient matrix to dense array format.\n",
            " |      \n",
            " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
            " |      default format of ``coef_`` and is required for fitting, so calling\n",
            " |      this method is only required on models that have previously been\n",
            " |      sparsified; otherwise, it is a no-op.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  sparsify(self)\n",
            " |      Convert coefficient matrix to sparse format.\n",
            " |      \n",
            " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
            " |      L1-regularized models can be much more memory- and storage-efficient\n",
            " |      than the usual numpy.ndarray representation.\n",
            " |      \n",
            " |      The ``intercept_`` member is not converted.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |          Fitted estimator.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
            " |      this may actually *increase* memory usage, so use this method with\n",
            " |      care. A rule of thumb is that the number of zero elements, which can\n",
            " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
            " |      to provide significant benefits.\n",
            " |      \n",
            " |      After calling this method, further fitting with the partial_fit\n",
            " |      method (if any) will not work until you call densify.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicionario  = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "cv = RepeatedKFold(n_splits = 5, n_repeats=10)\n",
        "y = dados_tratados[\"ICU\"]\n",
        "x = dados_tratados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=6000),dicionario, scoring=\"roc_auc\",cv=cv,return_train_score=True)\n",
        "resultados= grid.fit(x,y)"
      ],
      "metadata": {
        "id": "yUt-aSe2C_1r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Melhor: %f usando %s' %(resultados.best_score_, resultados.best_params_))\n",
        "means = resultados.cv_results_['mean_test_score']\n",
        "stds = resultados.cv_results_['std_test_score']\n",
        "params = resultados.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f'{mean:.3%} ({(mean-2*stdev):.3%} - {(mean+2*stdev):.3%}): {param}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzC5ojDGi4By",
        "outputId": "4b3dc586-929d-44c4-f9a2-493e907dba39"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor: 0.876230 usando {'solver': 'newton-cg'}\n",
            "87.623% (84.153% - 91.093%): {'solver': 'newton-cg'}\n",
            "87.623% (84.154% - 91.091%): {'solver': 'lbfgs'}\n",
            "87.593% (84.104% - 91.082%): {'solver': 'liblinear'}\n",
            "87.593% (84.105% - 91.081%): {'solver': 'sag'}\n",
            "87.595% (84.108% - 91.081%): {'solver': 'saga'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicionario  = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "cv = RepeatedKFold(n_splits = 5, n_repeats=10)\n",
        "y = dados_tratados_OHE[\"ICU\"]\n",
        "x = dados_tratados_OHE.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=6000),dicionario, scoring=\"roc_auc\",cv=cv,return_train_score=True)\n",
        "resultados_OHE= grid.fit(x,y)"
      ],
      "metadata": {
        "id": "QnapjcV3rC8X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Melhor: {resultados_OHE.best_score_:.3%} usando {resultados_OHE.best_params_}')\n",
        "means = resultados_OHE.cv_results_['mean_test_score']\n",
        "stds = resultados_OHE.cv_results_['std_test_score']\n",
        "params = resultados_OHE.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f'{mean:.3%} ({(mean-2*stdev):.3%} - {(mean+2*stdev):.3%}): {param}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvUx9T-mkFEU",
        "outputId": "d65861f4-a0a1-4f6b-a73e-a73e18cccd2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor: 87.658% usando {'solver': 'lbfgs'}\n",
            "87.657% (84.283% - 91.030%): {'solver': 'newton-cg'}\n",
            "87.658% (84.283% - 91.033%): {'solver': 'lbfgs'}\n",
            "87.614% (84.273% - 90.956%): {'solver': 'liblinear'}\n",
            "87.616% (84.273% - 90.959%): {'solver': 'sag'}\n",
            "87.617% (84.273% - 90.960%): {'solver': 'saga'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVLJxupBmwnd",
        "outputId": "bbdd5b23-b549-4115-9fc2-cb6d70e7a1d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_estimator_': LogisticRegression(max_iter=6000, solver='newton-cg'),\n",
              " 'best_index_': 0,\n",
              " 'best_params_': {'solver': 'newton-cg'},\n",
              " 'best_score_': 0.8762303648360767,\n",
              " 'cv': RepeatedKFold(n_repeats=10, n_splits=5, random_state=None),\n",
              " 'cv_results_': {'mean_fit_time': array([0.13628386, 0.29170593, 0.08037552, 0.6257951 , 1.20032635]),\n",
              "  'mean_score_time': array([0.00824224, 0.00789158, 0.00812408, 0.00701692, 0.00709614]),\n",
              "  'mean_test_score': array([0.87623036, 0.87622653, 0.87593148, 0.87593046, 0.87594531]),\n",
              "  'mean_train_score': array([0.89859384, 0.89859317, 0.89847351, 0.89846309, 0.89842049]),\n",
              "  'param_solver': masked_array(data=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
              "               mask=[False, False, False, False, False],\n",
              "         fill_value='?',\n",
              "              dtype=object),\n",
              "  'params': [{'solver': 'newton-cg'},\n",
              "   {'solver': 'lbfgs'},\n",
              "   {'solver': 'liblinear'},\n",
              "   {'solver': 'sag'},\n",
              "   {'solver': 'saga'}],\n",
              "  'rank_test_score': array([1, 2, 4, 5, 3], dtype=int32),\n",
              "  'split0_test_score': array([0.86693594, 0.86687905, 0.86710661, 0.86699283, 0.86727728]),\n",
              "  'split0_train_score': array([0.90082472, 0.90078867, 0.90070577, 0.90068054, 0.9005724 ]),\n",
              "  'split10_test_score': array([0.89056079, 0.89031907, 0.89056079, 0.8903795 , 0.89043993]),\n",
              "  'split10_train_score': array([0.89604904, 0.89607393, 0.89587837, 0.89587837, 0.89583926]),\n",
              "  'split11_test_score': array([0.84365634, 0.84360084, 0.84310134, 0.84321234, 0.84326784]),\n",
              "  'split11_train_score': array([0.90826777, 0.90829319, 0.90819516, 0.9081516 , 0.90814797]),\n",
              "  'split12_test_score': array([0.89483794, 0.89483794, 0.89465786, 0.89471789, 0.89471789]),\n",
              "  'split12_train_score': array([0.89638451, 0.89639875, 0.89647708, 0.89645928, 0.89641656]),\n",
              "  'split13_test_score': array([0.91029807, 0.91029807, 0.90962573, 0.9095697 , 0.9095697 ]),\n",
              "  'split13_train_score': array([0.89044066, 0.8904298 , 0.89073026, 0.89071216, 0.89070854]),\n",
              "  'split14_test_score': array([0.85342388, 0.8533107 , 0.85297114, 0.85302773, 0.85297114]),\n",
              "  'split14_train_score': array([0.90137708, 0.90138791, 0.90118938, 0.90118216, 0.9011605 ]),\n",
              "  'split15_test_score': array([0.85678334, 0.85678334, 0.85684054, 0.85701213, 0.85689774]),\n",
              "  'split15_train_score': array([0.90646788, 0.90649308, 0.90655787, 0.90653627, 0.90650028]),\n",
              "  'split16_test_score': array([0.85555556, 0.85578825, 0.85491565, 0.855032  , 0.855032  ]),\n",
              "  'split16_train_score': array([0.90192845, 0.90194279, 0.90208259, 0.90202165, 0.90192487]),\n",
              "  'split17_test_score': array([0.90262214, 0.90262214, 0.90335052, 0.90346257, 0.90335052]),\n",
              "  'split17_train_score': array([0.89311222, 0.89313032, 0.8929638 , 0.89293484, 0.8928733 ]),\n",
              "  'split18_test_score': array([0.89097612, 0.89109316, 0.89097612, 0.89097612, 0.89097612]),\n",
              "  'split18_train_score': array([0.89536911, 0.89539059, 0.89566263, 0.89559104, 0.8955624 ]),\n",
              "  'split19_test_score': array([0.89774436, 0.89774436, 0.89774436, 0.89774436, 0.89786003]),\n",
              "  'split19_train_score': array([0.89352645, 0.8935085 , 0.89333979, 0.89339005, 0.89333979]),\n",
              "  'split1_test_score': array([0.89072924, 0.89067173, 0.89084426, 0.89095928, 0.89101679]),\n",
              "  'split1_train_score': array([0.89576863, 0.89570034, 0.89521509, 0.89530495, 0.89528698]),\n",
              "  'split20_test_score': array([0.87016515, 0.87011082, 0.86951326, 0.86945893, 0.86945893]),\n",
              "  'split20_train_score': array([0.89957134, 0.89957134, 0.89944698, 0.89938846, 0.89937017]),\n",
              "  'split21_test_score': array([0.88754592, 0.88766442, 0.88707193, 0.88707193, 0.88707193]),\n",
              "  'split21_train_score': array([0.89774849, 0.8977235 , 0.89730583, 0.89729869, 0.89726299]),\n",
              "  'split22_test_score': array([0.87230805, 0.87224953, 0.87154728, 0.87154728, 0.87154728]),\n",
              "  'split22_train_score': array([0.89748463, 0.89745958, 0.89753833, 0.89754549, 0.89748821]),\n",
              "  'split23_test_score': array([0.88648139, 0.88648139, 0.886187  , 0.88606924, 0.88606924]),\n",
              "  'split23_train_score': array([0.89808897, 0.89811399, 0.89803177, 0.89800317, 0.8979567 ]),\n",
              "  'split24_test_score': array([0.86680469, 0.8668622 , 0.86691971, 0.86714976, 0.86726478]),\n",
              "  'split24_train_score': array([0.90095181, 0.90093024, 0.90078287, 0.9007613 , 0.90072895]),\n",
              "  'split25_test_score': array([0.87502876, 0.87497124, 0.87376352, 0.87364849, 0.87353347]),\n",
              "  'split25_train_score': array([0.89917256, 0.89919053, 0.89925164, 0.89919053, 0.89907911]),\n",
              "  'split26_test_score': array([0.88756906, 0.88751381, 0.88773481, 0.88773481, 0.88779006]),\n",
              "  'split26_train_score': array([0.89533522, 0.89531341, 0.89526978, 0.89523342, 0.89521888]),\n",
              "  'split27_test_score': array([0.89490108, 0.8948422 , 0.89407678, 0.89419454, 0.89407678]),\n",
              "  'split27_train_score': array([0.89274837, 0.89276982, 0.8923909 , 0.89238375, 0.892348  ]),\n",
              "  'split28_test_score': array([0.86530941, 0.86519439, 0.86617207, 0.86628709, 0.86640212]),\n",
              "  'split28_train_score': array([0.90177493, 0.90176055, 0.90182525, 0.90181447, 0.90180009]),\n",
              "  'split29_test_score': array([0.85674753, 0.85680641, 0.85680641, 0.85686528, 0.85698304]),\n",
              "  'split29_train_score': array([0.90256449, 0.90255019, 0.90250729, 0.90257164, 0.90253946]),\n",
              "  'split2_test_score': array([0.88376623, 0.88354978, 0.88327922, 0.88327922, 0.88333333]),\n",
              "  'split2_train_score': array([0.89824722, 0.89821792, 0.89826554, 0.89820693, 0.89815198]),\n",
              "  'split30_test_score': array([0.90872581, 0.90878666, 0.90750882, 0.90750882, 0.90750882]),\n",
              "  'split30_train_score': array([0.88906288, 0.88903803, 0.88900607, 0.8889315 , 0.88888889]),\n",
              "  'split31_test_score': array([0.88331333, 0.88319328, 0.88319328, 0.88313325, 0.88319328]),\n",
              "  'split31_train_score': array([0.89977748, 0.89979884, 0.8997312 , 0.89972764, 0.89970984]),\n",
              "  'split32_test_score': array([0.87382242, 0.8738813 , 0.87288036, 0.87282148, 0.87288036]),\n",
              "  'split32_train_score': array([0.89913278, 0.89911491, 0.8988611 , 0.89887898, 0.89879676]),\n",
              "  'split33_test_score': array([0.84398088, 0.84398088, 0.84430682, 0.84430682, 0.8442525 ]),\n",
              "  'split33_train_score': array([0.90656089, 0.90656089, 0.90622805, 0.90621342, 0.90616953]),\n",
              "  'split34_test_score': array([0.88176796, 0.8818232 , 0.88149171, 0.88149171, 0.88154696]),\n",
              "  'split34_train_score': array([0.89687682, 0.89685864, 0.89685137, 0.89685864, 0.89681137]),\n",
              "  'split35_test_score': array([0.86283644, 0.86272142, 0.86151369, 0.86168622, 0.86174373]),\n",
              "  'split35_train_score': array([0.90082241, 0.90085476, 0.90077208, 0.90077568, 0.9007002 ]),\n",
              "  'split36_test_score': array([0.9042162 , 0.90427748, 0.90415492, 0.9042162 , 0.90433877]),\n",
              "  'split36_train_score': array([0.89357703, 0.89360186, 0.89342454, 0.89343518, 0.89335362]),\n",
              "  'split37_test_score': array([0.85806303, 0.85794801, 0.85748792, 0.8573729 , 0.85731539]),\n",
              "  'split37_train_score': array([0.89893173, 0.89891376, 0.89885625, 0.89888501, 0.89880952]),\n",
              "  'split38_test_score': array([0.87347973, 0.87342342, 0.8732545 , 0.87331081, 0.87331081]),\n",
              "  'split38_train_score': array([0.89852516, 0.89856131, 0.89850709, 0.89849624, 0.89849263]),\n",
              "  'split39_test_score': array([0.86651054, 0.86651054, 0.86734694, 0.86723542, 0.86729118]),\n",
              "  'split39_train_score': array([0.90293789, 0.90292339, 0.90249561, 0.90252824, 0.90251374]),\n",
              "  'split3_test_score': array([0.88024023, 0.88029911, 0.88100565, 0.88071126, 0.88065238]),\n",
              "  'split3_train_score': array([0.89995138, 0.89995496, 0.89956532, 0.89955102, 0.8994688 ]),\n",
              "  'split40_test_score': array([0.89710749, 0.89704621, 0.89704621, 0.89704621, 0.89710749]),\n",
              "  'split40_train_score': array([0.89409478, 0.89411606, 0.89403095, 0.8939813 , 0.89399904]),\n",
              "  'split41_test_score': array([0.86041335, 0.86067833, 0.8609433 , 0.86073132, 0.86073132]),\n",
              "  'split41_train_score': array([0.90331084, 0.90329975, 0.90316665, 0.90316295, 0.9031038 ]),\n",
              "  'split42_test_score': array([0.87825691, 0.87825691, 0.8778018 , 0.87791558, 0.87785869]),\n",
              "  'split42_train_score': array([0.89935407, 0.89936848, 0.89920628, 0.89921709, 0.89918465]),\n",
              "  'split43_test_score': array([0.86101984, 0.86095899, 0.8596203 , 0.85955945, 0.8593769 ]),\n",
              "  'split43_train_score': array([0.90114303, 0.90112883, 0.90088737, 0.90087672, 0.90085186]),\n",
              "  'split44_test_score': array([0.88347877, 0.88347877, 0.88371146, 0.88365329, 0.88359511]),\n",
              "  'split44_train_score': array([0.89613592, 0.89617177, 0.89596745, 0.89590652, 0.89590652]),\n",
              "  'split45_test_score': array([0.8603656 , 0.86047126, 0.86025993, 0.86015427, 0.86015427]),\n",
              "  'split45_train_score': array([0.90135087, 0.90136198, 0.90133606, 0.90133606, 0.90127681]),\n",
              "  'split46_test_score': array([0.86581839, 0.86576056, 0.86431463, 0.86443031, 0.86448814]),\n",
              "  'split46_train_score': array([0.90099966, 0.90096735, 0.9008848 , 0.90094223, 0.90090633]),\n",
              "  'split47_test_score': array([0.89630292, 0.89636255, 0.89612403, 0.89618366, 0.89612403]),\n",
              "  'split47_train_score': array([0.89430303, 0.89426738, 0.89424599, 0.89420677, 0.89418538]),\n",
              "  'split48_test_score': array([0.89117647, 0.89123649, 0.89033613, 0.89039616, 0.89027611]),\n",
              "  'split48_train_score': array([0.89612105, 0.89609613, 0.89584691, 0.89585759, 0.89573298]),\n",
              "  'split49_test_score': array([0.85521765, 0.85527728, 0.85408468, 0.85402504, 0.85408468]),\n",
              "  'split49_train_score': array([0.9013369 , 0.90133333, 0.90099465, 0.90100891, 0.90100891]),\n",
              "  'split4_test_score': array([0.85320988, 0.85333333, 0.85271605, 0.85271605, 0.85271605]),\n",
              "  'split4_train_score': array([0.89939615, 0.89942448, 0.89929698, 0.89923678, 0.89930407]),\n",
              "  'split5_test_score': array([0.8689936 , 0.86905177, 0.86910995, 0.86910995, 0.86916812]),\n",
              "  'split5_train_score': array([0.90024733, 0.90024375, 0.89984587, 0.89987096, 0.89977059]),\n",
              "  'split6_test_score': array([0.84979129, 0.84973166, 0.84883721, 0.84883721, 0.84895647]),\n",
              "  'split6_train_score': array([0.90241711, 0.90241355, 0.90227807, 0.90228877, 0.90225312]),\n",
              "  'split7_test_score': array([0.90005013, 0.8999248 , 0.90111543, 0.9009901 , 0.9009901 ]),\n",
              "  'split7_train_score': array([0.89460688, 0.89461041, 0.89444085, 0.89441613, 0.89435254]),\n",
              "  'split8_test_score': array([0.87994982, 0.88005891, 0.87880441, 0.87880441, 0.87885895]),\n",
              "  'split8_train_score': array([0.89732268, 0.89732999, 0.89705974, 0.8970926 , 0.89705608]),\n",
              "  'split9_test_score': array([0.87265856, 0.87265856, 0.871837  , 0.87178223, 0.871837  ]),\n",
              "  'split9_train_score': array([0.89819056, 0.89820514, 0.89827443, 0.89823067, 0.8981395 ]),\n",
              "  'std_fit_time': array([0.0137918 , 0.02951593, 0.00538729, 0.03177138, 0.07841866]),\n",
              "  'std_score_time': array([0.00190687, 0.00070856, 0.00096601, 0.00102347, 0.00133429]),\n",
              "  'std_test_score': array([0.01735023, 0.01734323, 0.01744615, 0.01743959, 0.01743451]),\n",
              "  'std_train_score': array([0.0038932 , 0.0038955 , 0.00387967, 0.00388369, 0.00388374])},\n",
              " 'error_score': nan,\n",
              " 'estimator': LogisticRegression(max_iter=6000),\n",
              " 'feature_names_in_': array(['AGE_ABOVE65', 'AGE_PERCENTIL', 'GENDER', 'DISEASE GROUPING 1',\n",
              "        'DISEASE GROUPING 2', 'DISEASE GROUPING 3', 'DISEASE GROUPING 4',\n",
              "        'DISEASE GROUPING 5', 'DISEASE GROUPING 6', 'HTN',\n",
              "        'IMMUNOCOMPROMISED', 'OTHER', 'ALBUMIN_MEDIAN', 'ALBUMIN_MEAN',\n",
              "        'ALBUMIN_MIN', 'ALBUMIN_MAX', 'ALBUMIN_DIFF', 'BE_ARTERIAL_MEDIAN',\n",
              "        'BE_ARTERIAL_MEAN', 'BE_ARTERIAL_MIN', 'BE_ARTERIAL_MAX',\n",
              "        'BE_ARTERIAL_DIFF', 'BE_VENOUS_MEDIAN', 'BE_VENOUS_MEAN',\n",
              "        'BE_VENOUS_MIN', 'BE_VENOUS_MAX', 'BE_VENOUS_DIFF',\n",
              "        'BIC_ARTERIAL_MEDIAN', 'BIC_ARTERIAL_MEAN', 'BIC_ARTERIAL_MIN',\n",
              "        'BIC_ARTERIAL_MAX', 'BIC_ARTERIAL_DIFF', 'BIC_VENOUS_MEDIAN',\n",
              "        'BIC_VENOUS_MEAN', 'BIC_VENOUS_MIN', 'BIC_VENOUS_MAX',\n",
              "        'BIC_VENOUS_DIFF', 'BILLIRUBIN_MEDIAN', 'BILLIRUBIN_MEAN',\n",
              "        'BILLIRUBIN_MIN', 'BILLIRUBIN_MAX', 'BILLIRUBIN_DIFF',\n",
              "        'BLAST_MEDIAN', 'BLAST_MEAN', 'BLAST_MIN', 'BLAST_MAX',\n",
              "        'BLAST_DIFF', 'CALCIUM_MEDIAN', 'CALCIUM_MEAN', 'CALCIUM_MIN',\n",
              "        'CALCIUM_MAX', 'CALCIUM_DIFF', 'CREATININ_MEDIAN',\n",
              "        'CREATININ_MEAN', 'CREATININ_MIN', 'CREATININ_MAX',\n",
              "        'CREATININ_DIFF', 'FFA_MEDIAN', 'FFA_MEAN', 'FFA_MIN', 'FFA_MAX',\n",
              "        'FFA_DIFF', 'GGT_MEDIAN', 'GGT_MEAN', 'GGT_MIN', 'GGT_MAX',\n",
              "        'GGT_DIFF', 'GLUCOSE_MEDIAN', 'GLUCOSE_MEAN', 'GLUCOSE_MIN',\n",
              "        'GLUCOSE_MAX', 'GLUCOSE_DIFF', 'HEMATOCRITE_MEDIAN',\n",
              "        'HEMATOCRITE_MEAN', 'HEMATOCRITE_MIN', 'HEMATOCRITE_MAX',\n",
              "        'HEMATOCRITE_DIFF', 'HEMOGLOBIN_MEDIAN', 'HEMOGLOBIN_MEAN',\n",
              "        'HEMOGLOBIN_MIN', 'HEMOGLOBIN_MAX', 'HEMOGLOBIN_DIFF',\n",
              "        'INR_MEDIAN', 'INR_MEAN', 'INR_MIN', 'INR_MAX', 'INR_DIFF',\n",
              "        'LACTATE_MEDIAN', 'LACTATE_MEAN', 'LACTATE_MIN', 'LACTATE_MAX',\n",
              "        'LACTATE_DIFF', 'LEUKOCYTES_MEDIAN', 'LEUKOCYTES_MEAN',\n",
              "        'LEUKOCYTES_MIN', 'LEUKOCYTES_MAX', 'LEUKOCYTES_DIFF',\n",
              "        'LINFOCITOS_MEDIAN', 'LINFOCITOS_MEAN', 'LINFOCITOS_MIN',\n",
              "        'LINFOCITOS_MAX', 'LINFOCITOS_DIFF', 'NEUTROPHILES_MEDIAN',\n",
              "        'NEUTROPHILES_MEAN', 'NEUTROPHILES_MIN', 'NEUTROPHILES_MAX',\n",
              "        'NEUTROPHILES_DIFF', 'P02_ARTERIAL_MEDIAN', 'P02_ARTERIAL_MEAN',\n",
              "        'P02_ARTERIAL_MIN', 'P02_ARTERIAL_MAX', 'P02_ARTERIAL_DIFF',\n",
              "        'P02_VENOUS_MEDIAN', 'P02_VENOUS_MEAN', 'P02_VENOUS_MIN',\n",
              "        'P02_VENOUS_MAX', 'P02_VENOUS_DIFF', 'PC02_ARTERIAL_MEDIAN',\n",
              "        'PC02_ARTERIAL_MEAN', 'PC02_ARTERIAL_MIN', 'PC02_ARTERIAL_MAX',\n",
              "        'PC02_ARTERIAL_DIFF', 'PC02_VENOUS_MEDIAN', 'PC02_VENOUS_MEAN',\n",
              "        'PC02_VENOUS_MIN', 'PC02_VENOUS_MAX', 'PC02_VENOUS_DIFF',\n",
              "        'PCR_MEDIAN', 'PCR_MEAN', 'PCR_MIN', 'PCR_MAX', 'PCR_DIFF',\n",
              "        'PH_ARTERIAL_MEDIAN', 'PH_ARTERIAL_MEAN', 'PH_ARTERIAL_MIN',\n",
              "        'PH_ARTERIAL_MAX', 'PH_ARTERIAL_DIFF', 'PH_VENOUS_MEDIAN',\n",
              "        'PH_VENOUS_MEAN', 'PH_VENOUS_MIN', 'PH_VENOUS_MAX',\n",
              "        'PH_VENOUS_DIFF', 'PLATELETS_MEDIAN', 'PLATELETS_MEAN',\n",
              "        'PLATELETS_MIN', 'PLATELETS_MAX', 'PLATELETS_DIFF',\n",
              "        'POTASSIUM_MEDIAN', 'POTASSIUM_MEAN', 'POTASSIUM_MIN',\n",
              "        'POTASSIUM_MAX', 'POTASSIUM_DIFF', 'SAT02_ARTERIAL_MEDIAN',\n",
              "        'SAT02_ARTERIAL_MEAN', 'SAT02_ARTERIAL_MIN', 'SAT02_ARTERIAL_MAX',\n",
              "        'SAT02_ARTERIAL_DIFF', 'SAT02_VENOUS_MEDIAN', 'SAT02_VENOUS_MEAN',\n",
              "        'SAT02_VENOUS_MIN', 'SAT02_VENOUS_MAX', 'SAT02_VENOUS_DIFF',\n",
              "        'SODIUM_MEDIAN', 'SODIUM_MEAN', 'SODIUM_MIN', 'SODIUM_MAX',\n",
              "        'SODIUM_DIFF', 'TGO_MEDIAN', 'TGO_MEAN', 'TGO_MIN', 'TGO_MAX',\n",
              "        'TGO_DIFF', 'TGP_MEDIAN', 'TGP_MEAN', 'TGP_MIN', 'TGP_MAX',\n",
              "        'TGP_DIFF', 'TTPA_MEDIAN', 'TTPA_MEAN', 'TTPA_MIN', 'TTPA_MAX',\n",
              "        'TTPA_DIFF', 'UREA_MEDIAN', 'UREA_MEAN', 'UREA_MIN', 'UREA_MAX',\n",
              "        'UREA_DIFF', 'DIMER_MEDIAN', 'DIMER_MEAN', 'DIMER_MIN',\n",
              "        'DIMER_MAX', 'DIMER_DIFF', 'BLOODPRESSURE_DIASTOLIC_MEAN',\n",
              "        'BLOODPRESSURE_SISTOLIC_MEAN', 'HEART_RATE_MEAN',\n",
              "        'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN',\n",
              "        'OXYGEN_SATURATION_MEAN', 'BLOODPRESSURE_DIASTOLIC_MEDIAN',\n",
              "        'BLOODPRESSURE_SISTOLIC_MEDIAN', 'HEART_RATE_MEDIAN',\n",
              "        'RESPIRATORY_RATE_MEDIAN', 'TEMPERATURE_MEDIAN',\n",
              "        'OXYGEN_SATURATION_MEDIAN', 'BLOODPRESSURE_DIASTOLIC_MIN',\n",
              "        'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN',\n",
              "        'RESPIRATORY_RATE_MIN', 'TEMPERATURE_MIN', 'OXYGEN_SATURATION_MIN',\n",
              "        'BLOODPRESSURE_DIASTOLIC_MAX', 'BLOODPRESSURE_SISTOLIC_MAX',\n",
              "        'HEART_RATE_MAX', 'RESPIRATORY_RATE_MAX', 'TEMPERATURE_MAX',\n",
              "        'OXYGEN_SATURATION_MAX', 'BLOODPRESSURE_DIASTOLIC_DIFF',\n",
              "        'BLOODPRESSURE_SISTOLIC_DIFF', 'HEART_RATE_DIFF',\n",
              "        'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF',\n",
              "        'OXYGEN_SATURATION_DIFF', 'BLOODPRESSURE_DIASTOLIC_DIFF_REL',\n",
              "        'BLOODPRESSURE_SISTOLIC_DIFF_REL', 'HEART_RATE_DIFF_REL',\n",
              "        'RESPIRATORY_RATE_DIFF_REL', 'TEMPERATURE_DIFF_REL',\n",
              "        'OXYGEN_SATURATION_DIFF_REL'], dtype=object),\n",
              " 'multimetric_': False,\n",
              " 'n_jobs': None,\n",
              " 'n_splits_': 50,\n",
              " 'param_grid': {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
              " 'pre_dispatch': '2*n_jobs',\n",
              " 'refit': True,\n",
              " 'refit_time_': 0.15518450736999512,\n",
              " 'return_train_score': True,\n",
              " 'scorer_': make_scorer(roc_auc_score, needs_threshold=True),\n",
              " 'scoring': 'roc_auc',\n",
              " 'verbose': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x=[]\n",
        "for item in resultados.cv_results_['params']:\n",
        "  x.append(item['solver'])\n",
        "plt.plot(x, resultados.cv_results_['mean_test_score'], color='orange')\n",
        "plt.plot(x, resultados.cv_results_['mean_train_score'], color='blue')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4Kqb9hWknQ7U",
        "outputId": "879a45c0-17b4-467c-de46-b3053d2ab5eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f23696c7ad0>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GklBsMLe3tBr"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}